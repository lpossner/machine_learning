{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/kaggle/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.25.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/var/folders/3f/d8gl3k3j0bn3wk_cqjvfm31w0000gn/T/ipykernel_15563/907899923.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_titanic.loc[:, train_X_titanic_ordinal_columns] = OrdinalEncoder().fit_transform(X_titanic[train_X_titanic_ordinal_columns])\n",
      "/var/folders/3f/d8gl3k3j0bn3wk_cqjvfm31w0000gn/T/ipykernel_15563/907899923.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_machine_failure.loc[:, train_X_machine_failure_ordinal_columns] = OrdinalEncoder().fit_transform(X_machine_failure[train_X_machine_failure_ordinal_columns])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "## Titanic\n",
    "data_titanic = pd.read_csv(\"data/titanic/train.csv\")\n",
    "\n",
    "column_titanic_dict = {\"PassengerId\": \"PassengerId\", \"Survived\": \"Survived\", \"Pclass\": \"TicketClass\", \"Name\": \"Name\", \"Sex\": \"Sex\", \"Age\": \"Age\", \"SibSp\": \"NumberSiblingsSpouses\", \"Parch\": \"NumberParentsChildren\", \"Ticket\": \"TicketNumber\", \"Fare\": \"Fare\", \"Cabin\": \"CabinNumber\", \"Embarked\": \"Port\"}\n",
    "data_titanic = data_titanic.rename(columns=column_titanic_dict)\n",
    "\n",
    "train_X_titanic_columns = [\"TicketClass\", \"Sex\", \"Age\", \"NumberSiblingsSpouses\", \"NumberParentsChildren\", \"Fare\", \"Port\"]\n",
    "train_y_titanic_columns = [\"Survived\"]\n",
    "train_X_titanic_ordinal_columns = [\"Sex\", \"Port\"]\n",
    "\n",
    "X_titanic = data_titanic[train_X_titanic_columns]\n",
    "y_titanic = data_titanic[train_y_titanic_columns]\n",
    " \n",
    "X_titanic.loc[:, train_X_titanic_ordinal_columns] = OrdinalEncoder().fit_transform(X_titanic[train_X_titanic_ordinal_columns])\n",
    "\n",
    "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = train_test_split(X_titanic, y_titanic, test_size=0.4)\n",
    "y_titanic_train = np.squeeze(y_titanic_train)\n",
    "y_titanic_test = np.squeeze(y_titanic_test)\n",
    "\n",
    "## Machine Failure\n",
    "data_machine_failure = pd.read_csv(\"data/machine_failure/train.csv\")\n",
    "\n",
    "column_machine_failure_dict = {\"PassengerId\": \"PassengerId\", \"Survived\": \"Survived\", \"Pclass\": \"TicketClass\", \"Name\": \"Name\", \"Sex\": \"Sex\", \"Age\": \"Age\", \"SibSp\": \"NumberSiblingsSpouses\", \"Parch\": \"NumberParentsChildren\", \"Ticket\": \"TicketNumber\", \"Fare\": \"Fare\", \"Cabin\": \"CabinNumber\", \"Embarked\": \"Port\"}\n",
    "data_machine_failure = data_machine_failure.rename(columns=column_machine_failure_dict)\n",
    "\n",
    "train_X_machine_failure_columns = [\"TicketClass\", \"Sex\", \"Age\", \"NumberSiblingsSpouses\", \"NumberParentsChildren\", \"Fare\", \"Port\"]\n",
    "train_y_machine_failure_columns = [\"Survived\"]\n",
    "train_X_machine_failure_ordinal_columns = [\"Sex\", \"Port\"]\n",
    "\n",
    "X_machine_failure = data_machine_failure[train_X_machine_failure_columns]\n",
    "y_machine_failure = data_machine_failure[train_y_machine_failure_columns]\n",
    " \n",
    "X_machine_failure.loc[:, train_X_machine_failure_ordinal_columns] = OrdinalEncoder().fit_transform(X_machine_failure[train_X_machine_failure_ordinal_columns])\n",
    "\n",
    "X_machine_failure_train, X_machine_failure_test, y_machine_failure_train, y_machine_failure_test = train_test_split(X_machine_failure, y_machine_failure, test_size=0.4)\n",
    "y_machine_failure_train = np.squeeze(y_machine_failure_train)\n",
    "y_machine_failure_test = np.squeeze(y_machine_failure_test)\n",
    "\n",
    "## Synthetic\n",
    "X_synthetic = np.random.randn(int(3e3)).reshape([int(1e3), 3])\n",
    "y_synthetic = X_synthetic[:, 0] + X_synthetic[:, 1] + X_synthetic[:, 2] > 0\n",
    "yn_synthetic = np.logical_not(y_synthetic)\n",
    "\n",
    "X_synthetic[y_synthetic, :] += np.array([1, 1, 1]) * 0.1\n",
    "X_synthetic[yn_synthetic, :] -= np.array([1, 1, 1]) * 0.1\n",
    "\n",
    "X_synthetic_train, X_synthetic_test, y_synthetic_train, y_synthetic_test = train_test_split(X_synthetic, y_synthetic, test_size=0.4)\n",
    "y_synthetic_train = np.squeeze(y_synthetic_train)\n",
    "y_synthetic_test = np.squeeze(y_synthetic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic\n",
      "Confusion Matrix\n",
      "[[197  32]\n",
      " [ 36  92]]\n",
      "Precision Score\n",
      "0.7419354838709677\n",
      "Accuracy Score\n",
      "0.8095238095238095\n",
      "Recall Score\n",
      "0.71875\n",
      "F1 Score\n",
      "0.7301587301587302\n",
      "Best Estimator\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
      "                ('logr_clf',\n",
      "                 LogisticRegression(C=0.160371874375133,\n",
      "                                    multi_class='multinomial'))])\n",
      "Best Parameters\n",
      "{'logr_clf__C': 0.160371874375133, 'logr_clf__multi_class': 'multinomial', 'logr_clf__penalty': 'l2'}\n",
      "\n",
      "Machine Failure\n",
      "Confusion Matrix\n",
      "[[191  28]\n",
      " [ 38 100]]\n",
      "Precision Score\n",
      "0.78125\n",
      "Accuracy Score\n",
      "0.8151260504201681\n",
      "Recall Score\n",
      "0.7246376811594203\n",
      "F1 Score\n",
      "0.7518796992481203\n",
      "Best Estimator\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
      "                ('logr_clf', LogisticRegression(C=0.1))])\n",
      "Best Parameters\n",
      "{'logr_clf__C': 0.1, 'logr_clf__multi_class': 'auto', 'logr_clf__penalty': 'l2'}\n",
      "\n",
      "Synthetic\n",
      "Confusion Matrix\n",
      "[[193   0]\n",
      " [  0 207]]\n",
      "Precision Score\n",
      "1.0\n",
      "Accuracy Score\n",
      "1.0\n",
      "Recall Score\n",
      "1.0\n",
      "F1 Score\n",
      "1.0\n",
      "Best Estimator\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', StandardScaler()),\n",
      "                ('logr_clf', LogisticRegression(C=0.1))])\n",
      "Best Parameters\n",
      "{'logr_clf__C': 0.1, 'logr_clf__multi_class': 'auto', 'logr_clf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## Standard Scaler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "param_grid = [\n",
    "  {\"logr_clf__penalty\": [\"l2\"],\n",
    "   \"logr_clf__C\": np.logspace(-1, 3, 40),\n",
    "   \"logr_clf__multi_class\": [\"auto\", \"ovr\", \"multinomial\"]}\n",
    "]\n",
    "\n",
    "logr_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logr_clf\", LogisticRegression()),]),\n",
    "    param_grid, cv=10, verbose=0)\n",
    "\n",
    "## Titanic\n",
    "print(\"Titanic\")\n",
    "logr_clf.fit(X_titanic_train, y_titanic_train)\n",
    "y_titanic_lda_clf_pred = logr_clf.predict(X_titanic_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"Best Estimator\")\n",
    "print(logr_clf.best_estimator_)\n",
    "print(\"Best Parameters\")\n",
    "print(logr_clf.best_params_)\n",
    "\n",
    "print(\"\")\n",
    "## Machine Failure\n",
    "print(\"Machine Failure\")\n",
    "logr_clf.fit(X_machine_failure_train, y_machine_failure_train)\n",
    "y_machine_failure_lda_clf_pred = logr_clf.predict(X_machine_failure_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"Best Estimator\")\n",
    "print(logr_clf.best_estimator_)\n",
    "print(\"Best Parameters\")\n",
    "print(logr_clf.best_params_)\n",
    "\n",
    "print(\"\")\n",
    "## Synthetic\n",
    "print(\"Synthetic\")\n",
    "logr_clf.fit(X_synthetic_train, y_synthetic_train)\n",
    "y_synthetic_lda_clf_pred = logr_clf.predict(X_synthetic_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"Best Estimator\")\n",
    "print(logr_clf.best_estimator_)\n",
    "print(\"Best Parameters\")\n",
    "print(logr_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic\n",
      "Confusion Matrix\n",
      "[[195  34]\n",
      " [ 36  92]]\n",
      "Precision Score\n",
      "0.7301587301587301\n",
      "Accuracy Score\n",
      "0.803921568627451\n",
      "Recall Score\n",
      "0.71875\n",
      "F1 Score\n",
      "0.7244094488188977\n",
      "Best Estimator\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('logr_clf',\n",
      "                 LogisticRegression(C=0.3257020655659783,\n",
      "                                    multi_class='multinomial'))])\n",
      "Best Parameters\n",
      "{'logr_clf__C': 0.3257020655659783, 'logr_clf__multi_class': 'multinomial', 'logr_clf__penalty': 'l2'}\n",
      "\n",
      "Machine Failure\n",
      "Confusion Matrix\n",
      "[[187  32]\n",
      " [ 37 101]]\n",
      "Precision Score\n",
      "0.7593984962406015\n",
      "Accuracy Score\n",
      "0.8067226890756303\n",
      "Recall Score\n",
      "0.7318840579710145\n",
      "F1 Score\n",
      "0.7453874538745388\n",
      "Best Estimator\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('logr_clf',\n",
      "                 LogisticRegression(C=0.160371874375133,\n",
      "                                    multi_class='multinomial'))])\n",
      "Best Parameters\n",
      "{'logr_clf__C': 0.160371874375133, 'logr_clf__multi_class': 'multinomial', 'logr_clf__penalty': 'l2'}\n",
      "\n",
      "Synthetic\n",
      "Confusion Matrix\n",
      "[[193   0]\n",
      " [  0 207]]\n",
      "Precision Score\n",
      "1.0\n",
      "Accuracy Score\n",
      "1.0\n",
      "Recall Score\n",
      "1.0\n",
      "F1 Score\n",
      "1.0\n",
      "Best Estimator\n",
      "Pipeline(steps=[('imputer', SimpleImputer()), ('scaler', MinMaxScaler()),\n",
      "                ('logr_clf',\n",
      "                 LogisticRegression(C=0.5223345074266842,\n",
      "                                    multi_class='multinomial'))])\n",
      "Best Parameters\n",
      "{'logr_clf__C': 0.5223345074266842, 'logr_clf__multi_class': 'multinomial', 'logr_clf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## Min Max Scaler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "param_grid = [\n",
    "  {\"logr_clf__penalty\": [\"l2\"],\n",
    "   \"logr_clf__C\": np.logspace(-1, 3, 40),\n",
    "   \"logr_clf__multi_class\": [\"auto\", \"ovr\", \"multinomial\"]}\n",
    "]\n",
    "\n",
    "logr_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", MinMaxScaler()),\n",
    "    (\"logr_clf\", LogisticRegression()),]),\n",
    "    param_grid, cv=10, verbose=0)\n",
    "\n",
    "## Titanic\n",
    "print(\"Titanic\")\n",
    "logr_clf.fit(X_titanic_train, y_titanic_train)\n",
    "y_titanic_lda_clf_pred = logr_clf.predict(X_titanic_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_titanic_test, y_titanic_lda_clf_pred))\n",
    "print(\"Best Estimator\")\n",
    "print(logr_clf.best_estimator_)\n",
    "print(\"Best Parameters\")\n",
    "print(logr_clf.best_params_)\n",
    "\n",
    "print(\"\")\n",
    "## Machine Failure\n",
    "print(\"Machine Failure\")\n",
    "logr_clf.fit(X_machine_failure_train, y_machine_failure_train)\n",
    "y_machine_failure_lda_clf_pred = logr_clf.predict(X_machine_failure_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_machine_failure_test, y_machine_failure_lda_clf_pred))\n",
    "print(\"Best Estimator\")\n",
    "print(logr_clf.best_estimator_)\n",
    "print(\"Best Parameters\")\n",
    "print(logr_clf.best_params_)\n",
    "\n",
    "print(\"\")\n",
    "## Synthetic\n",
    "print(\"Synthetic\")\n",
    "logr_clf.fit(X_synthetic_train, y_synthetic_train)\n",
    "y_synthetic_lda_clf_pred = logr_clf.predict(X_synthetic_test)\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_synthetic_test, y_synthetic_lda_clf_pred))\n",
    "print(\"Best Estimator\")\n",
    "print(logr_clf.best_estimator_)\n",
    "print(\"Best Parameters\")\n",
    "print(logr_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
