{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3f/d8gl3k3j0bn3wk_cqjvfm31w0000gn/T/ipykernel_17443/907899923.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_titanic.loc[:, train_X_titanic_ordinal_columns] = OrdinalEncoder().fit_transform(X_titanic[train_X_titanic_ordinal_columns])\n",
      "/var/folders/3f/d8gl3k3j0bn3wk_cqjvfm31w0000gn/T/ipykernel_17443/907899923.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_machine_failure.loc[:, train_X_machine_failure_ordinal_columns] = OrdinalEncoder().fit_transform(X_machine_failure[train_X_machine_failure_ordinal_columns])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "## Titanic\n",
    "data_titanic = pd.read_csv(\"data/titanic/train.csv\")\n",
    "\n",
    "column_titanic_dict = {\"PassengerId\": \"PassengerId\", \"Survived\": \"Survived\", \"Pclass\": \"TicketClass\", \"Name\": \"Name\", \"Sex\": \"Sex\", \"Age\": \"Age\", \"SibSp\": \"NumberSiblingsSpouses\", \"Parch\": \"NumberParentsChildren\", \"Ticket\": \"TicketNumber\", \"Fare\": \"Fare\", \"Cabin\": \"CabinNumber\", \"Embarked\": \"Port\"}\n",
    "data_titanic = data_titanic.rename(columns=column_titanic_dict)\n",
    "\n",
    "train_X_titanic_columns = [\"TicketClass\", \"Sex\", \"Age\", \"NumberSiblingsSpouses\", \"NumberParentsChildren\", \"Fare\", \"Port\"]\n",
    "train_y_titanic_columns = [\"Survived\"]\n",
    "train_X_titanic_ordinal_columns = [\"Sex\", \"Port\"]\n",
    "\n",
    "X_titanic = data_titanic[train_X_titanic_columns]\n",
    "y_titanic = data_titanic[train_y_titanic_columns]\n",
    " \n",
    "X_titanic.loc[:, train_X_titanic_ordinal_columns] = OrdinalEncoder().fit_transform(X_titanic[train_X_titanic_ordinal_columns])\n",
    "\n",
    "X_titanic_train, X_titanic_test, y_titanic_train, y_titanic_test = train_test_split(X_titanic, y_titanic, test_size=0.4)\n",
    "y_titanic_train = np.squeeze(y_titanic_train)\n",
    "y_titanic_test = np.squeeze(y_titanic_test)\n",
    "\n",
    "## Machine Failure\n",
    "data_machine_failure = pd.read_csv(\"data/machine_failure/train.csv\")\n",
    "\n",
    "column_machine_failure_dict = {\"PassengerId\": \"PassengerId\", \"Survived\": \"Survived\", \"Pclass\": \"TicketClass\", \"Name\": \"Name\", \"Sex\": \"Sex\", \"Age\": \"Age\", \"SibSp\": \"NumberSiblingsSpouses\", \"Parch\": \"NumberParentsChildren\", \"Ticket\": \"TicketNumber\", \"Fare\": \"Fare\", \"Cabin\": \"CabinNumber\", \"Embarked\": \"Port\"}\n",
    "data_machine_failure = data_machine_failure.rename(columns=column_machine_failure_dict)\n",
    "\n",
    "train_X_machine_failure_columns = [\"TicketClass\", \"Sex\", \"Age\", \"NumberSiblingsSpouses\", \"NumberParentsChildren\", \"Fare\", \"Port\"]\n",
    "train_y_machine_failure_columns = [\"Survived\"]\n",
    "train_X_machine_failure_ordinal_columns = [\"Sex\", \"Port\"]\n",
    "\n",
    "X_machine_failure = data_machine_failure[train_X_machine_failure_columns]\n",
    "y_machine_failure = data_machine_failure[train_y_machine_failure_columns]\n",
    " \n",
    "X_machine_failure.loc[:, train_X_machine_failure_ordinal_columns] = OrdinalEncoder().fit_transform(X_machine_failure[train_X_machine_failure_ordinal_columns])\n",
    "\n",
    "X_machine_failure_train, X_machine_failure_test, y_machine_failure_train, y_machine_failure_test = train_test_split(X_machine_failure, y_machine_failure, test_size=0.4)\n",
    "y_machine_failure_train = np.squeeze(y_machine_failure_train)\n",
    "y_machine_failure_test = np.squeeze(y_machine_failure_test)\n",
    "\n",
    "## Synthetic\n",
    "X_synthetic = np.random.randn(int(3e3)).reshape([int(1e3), 3])\n",
    "y_synthetic = X_synthetic[:, 0] + X_synthetic[:, 1] + X_synthetic[:, 2] > 0\n",
    "yn_synthetic = np.logical_not(y_synthetic)\n",
    "\n",
    "X_synthetic[y_synthetic, :] += np.array([1, 1, 1]) * 0.1\n",
    "X_synthetic[yn_synthetic, :] -= np.array([1, 1, 1]) * 0.1\n",
    "\n",
    "X_synthetic_train, X_synthetic_test, y_synthetic_train, y_synthetic_test = train_test_split(X_synthetic, y_synthetic, test_size=0.4)\n",
    "y_synthetic_train = np.squeeze(y_synthetic_train)\n",
    "y_synthetic_test = np.squeeze(y_synthetic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic\n",
      "Optimize K Nearest Neighbors Classifier\n",
      "Optimize Logistic Regression Classifier\n",
      "Optimize Quadratic Discriminant Classifier\n",
      "Optimize Random Forest Classifier\n",
      "Optimize Ridge Regression Classifier\n",
      "Optimize SVM Classifier\n",
      "Confusion Matrix\n",
      "[[200  31]\n",
      " [ 35  91]]\n",
      "Precision Score\n",
      "0.7459016393442623\n",
      "Accuracy Score\n",
      "0.8151260504201681\n",
      "Recall Score\n",
      "0.7222222222222222\n",
      "F1 Score\n",
      "0.7338709677419354\n"
     ]
    }
   ],
   "source": [
    "## Standard Scaler\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, accuracy_score, recall_score\n",
    "\n",
    "## Titanic\n",
    "print(\"Titanic\")\n",
    "# K Nearest Neighbors Classifier\n",
    "print(\"Optimize K Nearest Neighbors Classifier\")\n",
    "knn_clf_param_grid = [\n",
    "  {\"knn_clf__n_neighbors\": [5, 10, 15, 20], \"knn_clf__weights\": [\"uniform\", \"distance\"]},\n",
    "]\n",
    "knn_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn_clf\", KNeighborsClassifier()),]),\n",
    "    knn_clf_param_grid, cv=10, verbose=0)\n",
    "knn_clf.fit(X_titanic_train, y_titanic_train)\n",
    "\n",
    "# Logistic Regression Classifier\n",
    "print(\"Optimize Logistic Regression Classifier\")\n",
    "logr_clf_param_grid = [\n",
    "  {\"logr_clf__penalty\": [\"l2\"],\n",
    "   \"logr_clf__C\": np.logspace(-1, 3, 40),\n",
    "   \"logr_clf__multi_class\": [\"auto\", \"ovr\", \"multinomial\"]}\n",
    "]\n",
    "logr_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logr_clf\", LogisticRegression()),]),\n",
    "    logr_clf_param_grid, cv=10, verbose=0)\n",
    "logr_clf.fit(X_titanic_train, y_titanic_train)\n",
    "\n",
    "# Quadratic Discriminant Classifier\n",
    "print(\"Optimize Quadratic Discriminant Classifier\")\n",
    "qda_clf = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"qda_clf\", QuadraticDiscriminantAnalysis()),])\n",
    "qda_clf.fit(X_titanic_train, y_titanic_train)\n",
    "\n",
    "# Random Forest Classifier\n",
    "print(\"Optimize Random Forest Classifier\")\n",
    "rnd_forest_clf_param_grid = [\n",
    "  {\"rnd_forest_clf__criterion\": [\"gini\", \"entropy\"], \"rnd_forest_clf__n_estimators\": [100, 200]},\n",
    "]\n",
    "rnd_forest_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rnd_forest_clf\", RandomForestClassifier()),]),\n",
    "    rnd_forest_clf_param_grid, cv=10, verbose=0)\n",
    "rnd_forest_clf.fit(X_titanic_train, y_titanic_train)\n",
    "\n",
    "# Ridge Regression Classifier\n",
    "print(\"Optimize Ridge Regression Classifier\")\n",
    "ridge_cv_clf = Pipeline([\n",
    "            (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"ridge_clf\", RidgeClassifierCV(alphas=np.logspace(-2, 2, 25), cv=5)),\n",
    "        ])\n",
    "ridge_cv_clf.fit(X_titanic_train, y_titanic_train)\n",
    "\n",
    "# SVM Classifier\n",
    "print(\"Optimize SVM Classifier\")\n",
    "param_grid = [\n",
    "  {\"svm_clf__C\": np.logspace(-1, 2, 15), \"svm_clf__kernel\": [\"linear\"]},\n",
    "  {\"svm_clf__C\": np.logspace(-1, 2, 15), \"svm_clf__kernel\": [\"poly\"], \"svm_clf__degree\": [1, 2, 3, 4, 5, 6]},\n",
    "  {\"svm_clf__C\": np.logspace(-1, 2, 15), \"svm_clf__kernel\": [\"rbf\"]},\n",
    "  {\"svm_clf__C\": np.logspace(-1, 2, 15), \"svm_clf__kernel\": [\"rbf\"]},\n",
    "  {\"svm_clf__C\": np.logspace(-1, 2, 15), \"svm_clf__kernel\": [\"sigmoid\"]},\n",
    "]\n",
    "svm_clf = GridSearchCV(Pipeline([\n",
    "    (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"mean\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", SVC()),]),\n",
    "    param_grid, cv=3, verbose=0)\n",
    "svm_clf.fit(X_titanic_train, y_titanic_train)\n",
    "\n",
    "# Voting Classifier\n",
    "vtg_clf = VotingClassifier([(\"knn_clf\", knn_clf.best_estimator_), (\"logr_clf\", logr_clf.best_estimator_), (\"qda_clf\", qda_clf), (\"rnd_forest_clf\", rnd_forest_clf.best_estimator_), (\"ridge_cv_clf\", ridge_cv_clf), (\"svm_clf\", svm_clf.best_estimator_)])\n",
    "vtg_clf.fit(X_titanic_train, y_titanic_train)\n",
    "y_titanic_vtg_clf_pred = vtg_clf.predict(X_titanic_test)\n",
    "\n",
    "# Score\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_titanic_test, y_titanic_vtg_clf_pred))\n",
    "print(\"Precision Score\")\n",
    "print(precision_score(y_titanic_test, y_titanic_vtg_clf_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(accuracy_score(y_titanic_test, y_titanic_vtg_clf_pred))\n",
    "print(\"Recall Score\")\n",
    "print(recall_score(y_titanic_test, y_titanic_vtg_clf_pred))\n",
    "print(\"F1 Score\")\n",
    "print(f1_score(y_titanic_test, y_titanic_vtg_clf_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
