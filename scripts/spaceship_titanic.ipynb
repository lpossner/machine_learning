{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/spaceship-titanic/train.csv\")\n",
    "# df['FirstName'] = df['Name'].apply(lambda name: name.split(' ')[0] if type(name) == str else None)\n",
    "\n",
    "# from transformers import pipeline\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# tqdm.pandas()\n",
    "\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"valhalla/distilbart-mnli-12-1\", device=\"mps\")\n",
    "# def predict_gender(name):\n",
    "#     result = None\n",
    "#     if name is not None:\n",
    "#         result = classifier(name, [\"male\", \"female\"])['labels'][0]\n",
    "#     return result\n",
    "\n",
    "# df['Gender'] = df['FirstName'].progress_apply(predict_gender)\n",
    "\n",
    "# print(df['Gender'])\n",
    "\n",
    "# df = df.drop(columns=['FirstName'])\n",
    "# df.to_csv('../data/spaceship-titanic/train_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/spaceship-titanic/test.csv\")\n",
    "# df['FirstName'] = df['Name'].apply(lambda name: name.split(' ')[0] if type(name) == str else None)\n",
    "\n",
    "# from transformers import pipeline\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# tqdm.pandas()\n",
    "\n",
    "# classifier = pipeline(\"zero-shot-classification\", model=\"valhalla/distilbart-mnli-12-1\", device=\"mps\")\n",
    "# def predict_gender(name):\n",
    "#     result = None\n",
    "#     if name is not None:\n",
    "#         result = classifier(name, [\"male\", \"female\"])['labels'][0]\n",
    "#     return result\n",
    "\n",
    "# df['Gender'] = df['FirstName'].progress_apply(predict_gender)\n",
    "\n",
    "# print(df['Gender'])\n",
    "\n",
    "# df = df.drop(columns=['FirstName'])\n",
    "# df.to_csv('../data/spaceship-titanic/test_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df):\n",
    "    df[[\"CabinDeck\", \"CabinNumber\", \"CabinSide\"]] = df['Cabin'].apply(lambda cabin: cabin.split(\"/\") if type(cabin) == str else [None, None, None]).apply(pd.Series)\n",
    "    df = df.drop(columns=[\"Cabin\"])\n",
    "\n",
    "    df[[\"PassengerGroup\", \"PassengerNumber\"]] = df['PassengerId'].apply(lambda passenger_id: [float(passenger_id_part) for passenger_id_part in passenger_id.split(\"_\")] if type(passenger_id) == str else [None, None]).apply(pd.Series)\n",
    "    df[\"PassengerGroup\"] = df[\"PassengerGroup\"].astype(float)\n",
    "    df[\"PassengerNumber\"] = df[\"PassengerNumber\"].astype(float)\n",
    "\n",
    "    df[\"Single\"] = False\n",
    "    df.loc[df[df[\"PassengerNumber\"] < 2][\"PassengerGroup\"].index, \"Single\"] = True\n",
    "\n",
    "    df[\"Couple\"] = False\n",
    "    df.loc[df[np.logical_and(2 < df[\"PassengerNumber\"], df[\"PassengerNumber\"] < 3)][\"PassengerGroup\"].index, \"Couple\"] = True\n",
    "\n",
    "    df[\"SmallGroup\"] = False\n",
    "    df.loc[df[np.logical_and(3 < df[\"PassengerNumber\"], df[\"PassengerNumber\"] < 6)][\"PassengerGroup\"].index, \"SmallGroup\"] = True\n",
    "\n",
    "    df[\"LargeGroup\"] = False\n",
    "    df.loc[df[df[\"PassengerNumber\"] > 6][\"PassengerGroup\"].index, \"LargeGroup\"] = True\n",
    "\n",
    "    df = df.drop(columns=[\"PassengerGroup\"])\n",
    "\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"HomePlanet\"], prefix=\"HomePlanet\")], axis=1)\n",
    "    df = df.drop(columns=[\"HomePlanet\"])\n",
    "\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"Destination\"], prefix=\"Destination\")], axis=1)\n",
    "    df = df.drop(columns=[\"Destination\"])\n",
    "\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"CabinDeck\"], prefix=\"CabinDeck\")], axis=1)\n",
    "    df = df.drop(columns=[\"CabinDeck\"])\n",
    "\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"CabinSide\"], prefix=\"CabinSide\")], axis=1)\n",
    "    df = df.drop(columns=[\"CabinSide\"])\n",
    "\n",
    "    df = pd.concat([df, pd.get_dummies(df[\"Gender\"], prefix=\"Gender\")], axis=1)\n",
    "    df = df.drop(columns=[\"Gender\"])\n",
    "\n",
    "    # df[\"CabinNumber\"] = df[\"CabinNumber\"].astype(float)\n",
    "    df = df.drop(columns=[\"CabinNumber\"])\n",
    "\n",
    "    df[\"CryoSleep\"] = df[\"CryoSleep\"].astype(bool)\n",
    "\n",
    "    df[\"VIP\"] = df[\"VIP\"].astype(bool)\n",
    "\n",
    "    spends = df[['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']].sum(axis=1)\n",
    "    iqr = spends.quantile(q=0.75) - spends.quantile(q=0.25)\n",
    "    df[\"Rich\"] = spends > spends.quantile(q=0.75) + 2 * iqr\n",
    "    df[\"Poor\"] = spends < spends.quantile(q=0.25)\n",
    "    df[\"Average\"] =  np.logical_and(spends.quantile(q=0.25) < spends, spends < spends.quantile(q=0.75) + 2 * iqr)\n",
    "\n",
    "    df = df.drop(columns=[\"Name\"])\n",
    "\n",
    "    for column in df:\n",
    "        if df[column].isna().any():\n",
    "            if df[column].dtype == float:\n",
    "                df[column] = SimpleImputer(strategy=\"median\").fit_transform(df[[column]])\n",
    "            if df[column].dtype == bool:\n",
    "                df[column] = SimpleImputer(strategy=\"most_frequent\").fit_transform(df[[column]])\n",
    "    \n",
    "    # df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_y(X, y=None):\n",
    "    float_mask = (X.dtypes == float).values\n",
    "\n",
    "    X.iloc[:, float_mask] = StandardScaler().fit_transform(X.iloc[:, float_mask])\n",
    "    X = X.astype(float)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "    y_tensor = None\n",
    "    if y is not None:\n",
    "        y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "\n",
    "    return X_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/spaceship-titanic/train.csv\")\n",
    "df = pd.read_csv(\"../data/spaceship-titanic/train_augmented.csv\")\n",
    "\n",
    "df = prepare_df(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[\"Transported\", \"PassengerId\"]), df[\"Transported\"], train_size=0.9)\n",
    "\n",
    "X_train_tensor, y_train_tensor = prepare_X_y(X=X_train, y=y_train)\n",
    "X_test_tensor, y_test_tensor = prepare_X_y(X=X_test, y=y_test)\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_size = X_train.shape[1]\n",
    "model = BinaryClassifier(input_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)  # Decay rate of 0.9\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor).squeeze()\n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        accuracy = (predictions == y_test_tensor).float().mean()\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor, y_tensor = prepare_X_y(df.drop(columns=[\"Transported\", \"PassengerId\"]), df[\"Transported\"])\n",
    "X_dataset = TensorDataset(X_tensor, y_tensor)\n",
    "X_loader = DataLoader(X_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "input_size = X_tensor.shape[1]\n",
    "model = BinaryClassifier(input_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-2)\n",
    "\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)  # Decay rate of 0.9\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in X_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test_tensor).squeeze()\n",
    "        predictions = (outputs >= 0.5).float()\n",
    "        accuracy = (predictions == y_test_tensor).float().mean()\n",
    "        print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.read_csv(\"../data/spaceship-titanic/test_augmented.csv\")\n",
    "df_comp = prepare_df(df_comp)\n",
    "\n",
    "passenger_id = df_comp.PassengerId.values\n",
    "\n",
    "X_tensor, _ = prepare_X_y(X=df_comp.drop(columns=[\"PassengerId\"]))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor).squeeze()\n",
    "    predictions = (outputs >= 0.5).float()\n",
    "\n",
    "data = np.stack([passenger_id, predictions.numpy().astype(bool)], axis=1)\n",
    "df_sub = pd.DataFrame(data=data, columns=[\"PassengerId\",\"Transported\"])\n",
    "df_sub.to_csv(\"../data/spaceship-titanic/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
