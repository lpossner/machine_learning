{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "train_neg_path = \"data/aclImdb/train/neg\"\n",
    "train_pos_path = \"data/aclImdb/train/neg\"\n",
    "\n",
    "\n",
    "def read_texts(path):\n",
    "    text_lst = []\n",
    "    for filename in os.listdir(path):\n",
    "        if filename[-4:] == '.txt':\n",
    "            with open(os.path.join(train_neg_path, filename), 'rt') as file:\n",
    "                text_lst.append(file.read())\n",
    "    return text_lst\n",
    "\n",
    "\n",
    "train_neg_texts = read_texts(train_neg_path)\n",
    "train_neg_labels = [0] * len(train_neg_texts)\n",
    "train_pos_texts = read_texts(train_pos_path)\n",
    "train_pos_labels = [1] * len(train_pos_texts)\n",
    "\n",
    "train_texts = train_neg_texts + train_pos_texts\n",
    "train_labels = train_neg_labels + train_pos_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "N_words = 10000\n",
    "N_tokens = 100\n",
    "N_training = 200\n",
    "N_validation = 10000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=N_words)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "sequences = tokenizer.texts_to_sequences(train_texts)\n",
    "word_index_dct = tokenizer.word_index\n",
    "X = pad_sequences(sequences, maxlen=N_tokens)\n",
    "y = np.array(train_labels)\n",
    "\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "X_train = X[:N_training]\n",
    "y_train = y[:N_training]\n",
    "X_val = X[N_training: N_training + N_validation]\n",
    "y_val = y[N_training: N_training + N_validation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "glove_dir = 'data/glove'\n",
    "\n",
    "embeddings_index_dct = {}\n",
    "with open(os.path.join(glove_dir, 'glove.6B.100d.txt'), 'rt') as file:\n",
    "    for line in file:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coeffs = np.asarray(values[1:], dtype=np.float32)\n",
    "        embeddings_index_dct[word] = coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_embedding_dim = 100\n",
    "embedding_matrix = np.zeros((N_words, N_embedding_dim))\n",
    "for word, word_index in word_index_dct.items():\n",
    "    if word_index <= N_words and word in embeddings_index_dct:\n",
    "        embedding_matrix[word_index-1] = embeddings_index_dct[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 20:07:53.380875: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-12-06 20:07:53.381102: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2023-12-06 20:07:53.381116: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2023-12-06 20:07:53.381406: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-06 20:07:53.381827: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 10000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                320032    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1320065 (5.04 MB)\n",
      "Trainable params: 1320065 (5.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(N_words, N_embedding_dim, input_length=N_tokens))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-06 20:12:43.856120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 4s 311ms/step - loss: 1.8591 - acc: 0.4650 - val_loss: 0.8670 - val_acc: 0.5015\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 1s 197ms/step - loss: 0.5414 - acc: 0.6950 - val_loss: 0.9605 - val_acc: 0.4978\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.5285 - acc: 0.6950 - val_loss: 0.8908 - val_acc: 0.5001\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.3905 - acc: 0.8150 - val_loss: 0.8618 - val_acc: 0.5019\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.3114 - acc: 0.8800 - val_loss: 1.0132 - val_acc: 0.4979\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.2516 - acc: 0.9550 - val_loss: 0.8203 - val_acc: 0.4995\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 0.2089 - acc: 0.9650 - val_loss: 1.0739 - val_acc: 0.4962\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 1s 192ms/step - loss: 0.1761 - acc: 0.9650 - val_loss: 0.8218 - val_acc: 0.4925\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.1241 - acc: 0.9900 - val_loss: 0.8301 - val_acc: 0.4921\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.0988 - acc: 0.9950 - val_loss: 0.8389 - val_acc: 0.4936\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
