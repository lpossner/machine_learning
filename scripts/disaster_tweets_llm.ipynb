{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lpossner/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "from openai import RateLimitError\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/nlp-getting-started/train.csv\")\n",
    "test_df = pd.read_csv(\"../data/nlp-getting-started/test.csv\")\n",
    "\n",
    "tweet_train_df = train_df[['text', 'target']]\n",
    "tweet_test_df = test_df[['id', 'text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+|www\\S+|https\\S+', '', tweet)\n",
    "    # Remove mentions\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    # Remove hashtags (optional to retain words)\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # Remove punctuation\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    # Remove emojis\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+', '', tweet)  # Removes non-ASCII characters (emojis)\n",
    "    # Convert to lowercase\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokenizer = TweetTokenizer()\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Reassemble tweet\n",
    "    cleaned_tweet = ' '.join(tokens)\n",
    "    return cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          deeds reason earthquake may allah forgive us\n",
       "1                 forest fire near la ronge sask canada\n",
       "2     residents asked shelter place notified officer...\n",
       "3     13000 people receive wildfires evacuation orde...\n",
       "4     got sent photo ruby alaska smoke wildfires pou...\n",
       "5     rockyfire update california hwy 20 closed dire...\n",
       "6     flood disaster heavy rain causes flash floodin...\n",
       "7                            im top hill see fire woods\n",
       "8     theres emergency evacuation happening building...\n",
       "9                         im afraid tornado coming area\n",
       "10                      three people died heat wave far\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train_df.loc[:, 'text'] = tweet_train_df['text'].apply(clean_tweet)\n",
    "tweet_test_df.loc[:, 'text'] = tweet_test_df['text'].apply(clean_tweet)\n",
    "\n",
    "tweet_train_df['text'].loc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a twitter tweet analysis assistant. You analyze if a tweet is about a natural disaster or not. Analyze the provided tweet and respond with 0 if the tweet is not about a natural disaser and 1 if it is. \n",
      "\n",
      "Example 1 \n",
      "Tweet: eau claire man police said drunk suv collided train sentenced chippewa county \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 2 \n",
      "Tweet: 11yearold boy charged manslaughter toddler report 11yearold boy charged manslaughter fatal sh \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 3 \n",
      "Tweet: watch airport get swallowed sandstorm minute \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 4 \n",
      "Tweet: warfighting robots could reduce civilian casualties calling ban premature ftsn ftsnnewsdesk _ \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 5 \n",
      "Tweet: manuel hoping early buffalo snowstorm accuracy improves \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 6 \n",
      "Tweet: imsort interested fonts theyre using \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 7 \n",
      "Tweet: due rainstorm last night cupcake decorating happening rec hall 2 proceeds iwk \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 8 \n",
      "Tweet: irandeal covers nuclear activity bioterrorism iran broken least 27 agreements \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 9 \n",
      "Tweet: still domestic terrorism \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 10 \n",
      "Tweet: hot reddits new content policy goes effect many horrible subreddits banned quarantined prebreak best \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 11 \n",
      "Tweet: 2 regular coffees rockstar coffee today im still tired \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 12 \n",
      "Tweet: australia news japan marks 70th anniversary hiroshima atomic bombing read \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 13 \n",
      "Tweet: rly tragedy mp live recount horror saw coaches train plunging water called \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 14 \n",
      "Tweet: wreckage conclusively confirmed mh370 malaysia pm investigators families \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 15 \n",
      "Tweet: sinkhole selfies wont believe whats brooklyn sinkhole sinkhole selfies wont belie \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 16 \n",
      "Tweet: leicester_merc icymi ashes 2015 australia collapse trent bridge twitter rea _ \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 17 \n",
      "Tweet: im blazing rn theres nothing stop \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 18 \n",
      "Tweet: gov brown links ca wildfire drought \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 19 \n",
      "Tweet: omg dont believe rip bro airplane accident jetengine turbojet boing g90 \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 20 \n",
      "Tweet: governor allows parole school bus hijacker \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 21 \n",
      "Tweet: 40 families affected fatal outbreak legionnaires disease edinburgh sue two comp \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 22 \n",
      "Tweet: ted cruz fires back jeb amp bush lose republicans like jeb amp mitt video \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 23 \n",
      "Tweet: weyburn police warn public fentanyl deaths province \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 24 \n",
      "Tweet: earthquake drill \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 25 \n",
      "Tweet: iraq hashd shaabi theft isis suicide car bomb isis \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 26 \n",
      "Tweet: beforeitsnews global derivatives 15 quadrillion time bomb v_ \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 27 \n",
      "Tweet: i405 southbound coal creek pkwy collision blocking center lane \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 28 \n",
      "Tweet: governor allows parole california school bus hijacker local \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 29 \n",
      "Tweet: fear looking like know doing_ahhh_that big one perrychat \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 30 \n",
      "Tweet: eudrylantiqua hollywood movie trapped miners released chile 33 holly eudrylantiqua \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 31 \n",
      "Tweet: feel engulfed low selfimage take quiz \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 32 \n",
      "Tweet: learning legacy catastrophic eruption new yorker \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 33 \n",
      "Tweet: nikoniko 12022 breaking news unconfirmed heard loud bang nearby appears blast wind neighbours ass \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 34 \n",
      "Tweet: god forbid anyone family knows answer phone need new emergency contacts \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 35 \n",
      "Tweet: white twister black shift knob m6x100 thread size \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 36 \n",
      "Tweet: 9503 bmw 528 530 540 740 emergency warning hazard switch button oem 2017770 7d \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 37 \n",
      "Tweet: tubestrike tfl workers may trouble planning downtime hope none need emergency services \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 38 \n",
      "Tweet: yiayplan use awesome collection amiibos destroy path \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 39 \n",
      "Tweet: weatherit needs make minds first snow tornadoes would say heat wave \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 40 \n",
      "Tweet: 3 former executives prosecuted fukushima nuclear disaster \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 41 \n",
      "Tweet: deals 37592 temporary fake tooth teeth replacement kit emergency dental oral care cosme _ \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 42 \n",
      "Tweet: cyclist collided runner roanoke greenway wins 300000 civil verdict roanoke times cyclist c \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 43 \n",
      "Tweet: tarp protecting outfield cannot moved infield getting deluged \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 44 \n",
      "Tweet: nosurrender results full metal mayhem world title match bully ray taken career comes end \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 45 \n",
      "Tweet: heard theres two deaths murder chrissie kills adam val finn die emmerdale \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 46 \n",
      "Tweet: builder dental emergency ruined plan emotionally blackmail afternoon bump \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 47 \n",
      "Tweet: must get hot burning buildings loses followers \n",
      "Is about natural disaster: 1 \n",
      "\n",
      "Example 48 \n",
      "Tweet: 16 stylishly unique houses might help survive zombie apocalypse \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 49 \n",
      "Tweet: annihilated status education mba behalf easy street careen eovm \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "Example 50 \n",
      "Tweet: deluge troisrivieres one hour get legionstrackandfield \n",
      "Is about natural disaster: 0 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "few_shot = 'You are a twitter tweet analysis assistant. You analyze if a tweet is about a natural disaster or not. Analyze the provided tweet and respond with 0 if the tweet is not about a natural disaser and 1 if it is. \\n\\n'\n",
    "for index, row in enumerate(tweet_train_df.sample(n=50).iterrows()):\n",
    "    few_shot += f'Example {index + 1} \\n'\n",
    "    few_shot += f'Tweet: {row[1]['text']} \\n'\n",
    "    few_shot += f'Is about natural disaster: {row[1]['target']} \\n\\n'\n",
    "\n",
    "print(few_shot)\n",
    "\n",
    "def is_natural_disaster_tweet(tweet, max_tries=3, delay=0.5):\n",
    "    prompt = few_shot + f'Now analyze the following tweet:\\nTweet: {tweet}\\nIs about natural disaster:'\n",
    "    for _ in range(max_tries):\n",
    "        try:\n",
    "            response = client.completions.create(\n",
    "                model=\"gpt-3.5-turbo-instruct\",\n",
    "                prompt=prompt,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            return response.choices[0].text.strip()\n",
    "        except RateLimitError as e:\n",
    "            exception = e\n",
    "            print(f'Rate limit exceeded. Wait for {delay*1000}ms and retry.')\n",
    "            time.sleep(delay)\n",
    "    raise exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 601/601 [08:55<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "tweet_val = tweet_train_df.loc[:600, 'text']\n",
    "target_val_list = tweet_train_df.loc[:600, 'target'].to_list()\n",
    "is_natural_disaster_list = [int(is_natural_disaster_tweet(tweet)) for tweet in tqdm(tweet_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.73\n",
      "Precision: 0.77\n",
      "Recall:    0.46\n",
      "F1 Score:  0.58\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(target_val_list, is_natural_disaster_list)\n",
    "precision = precision_score(target_val_list, is_natural_disaster_list)\n",
    "recall = recall_score(target_val_list, is_natural_disaster_list)\n",
    "f1 = f1_score(target_val_list, is_natural_disaster_list)\n",
    "\n",
    "print(f\"Accuracy:  {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall:    {recall:.2f}\")\n",
    "print(f\"F1 Score:  {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "language_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
