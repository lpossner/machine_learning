{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "\n",
    "# load_dotenv(override=True)\n",
    "# NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "# NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "# NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "# NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")\n",
    "# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "# OPENAI_ENDPOINT = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "# OPENAI_EMBEDDING_ENDPOINT = os.getenv(\"OPENAI_EMBEDDING_ENDPOINT\")\n",
    "\n",
    "# graph = Neo4jGraph(\n",
    "#     url=NEO4J_URI,\n",
    "#     username=NEO4J_USERNAME,\n",
    "#     password=NEO4J_PASSWORD,\n",
    "#     database=NEO4J_DATABASE,\n",
    "# )\n",
    "\n",
    "# graph.query(\n",
    "#     \"\"\"\n",
    "#   MATCH (n)\n",
    "#   MATCH (m:Movie)\n",
    "#   RETURN count(n) AS numberOfNodes, count(m) AS numberOfMovies\n",
    "#   \"\"\"\n",
    "# )\n",
    "\n",
    "# graph.query(\n",
    "#     \"\"\"\n",
    "# MATCH (tomCruise:Person {name: \"Tom Cruise\"})-[:ACTED_IN|DIRECTED]->(movie:Movie)\n",
    "# RETURN movie.title, movie.tagline, movie.released\n",
    "# ORDER BY movie.released DESC\n",
    "#   \"\"\"\n",
    "# )\n",
    "\n",
    "# graph.query(\n",
    "#     \"\"\"\n",
    "#   CREATE VECTOR INDEX movie_tagline_embeddings IF NOT EXISTS\n",
    "#   FOR (m:Movie) ON (m.taglineEmbedding) \n",
    "#   OPTIONS { indexConfig: {\n",
    "#     `vector.dimensions`: 1536,\n",
    "#     `vector.similarity_function`: 'cosine'\n",
    "#   }}\"\"\"\n",
    "# )\n",
    "\n",
    "# graph.query(\n",
    "#     \"\"\"\n",
    "#   SHOW VECTOR INDEXES\n",
    "#   \"\"\"\n",
    "# )\n",
    "\n",
    "# graph.query(\n",
    "#     \"\"\"\n",
    "#     MATCH (m:Movie) \n",
    "#     WHERE m.tagline IS NOT NULL\n",
    "#     RETURN m.tagline, m.taglineEmbedding\n",
    "#     LIMIT 1        \n",
    "#     \"\"\"\n",
    "# )\n",
    "\n",
    "# # from openai import OpenAI\n",
    "# # from tqdm import tqdm\n",
    "\n",
    "# # # Initialize OpenAI client\n",
    "# # client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# # # Fetch all movie taglines\n",
    "# # result = graph.query(\n",
    "# #     \"\"\"\n",
    "# #     MATCH (m:Movie)\n",
    "# #     WHERE m.tagline IS NOT NULL\n",
    "# #     RETURN m.title, m.tagline\n",
    "# #     \"\"\"\n",
    "# # )\n",
    "\n",
    "# # # Generate embeddings and update the graph\n",
    "# # for movie in tqdm(result):\n",
    "# #     title = movie[\"m.title\"]\n",
    "# #     tagline = movie[\"m.tagline\"]\n",
    "\n",
    "# #     # Generate embedding\n",
    "# #     response = client.embeddings.create(input=tagline, model=\"text-embedding-ada-002\")\n",
    "# #     embedding = response.data[0].embedding\n",
    "\n",
    "# #     # Update the graph\n",
    "# #     graph.query(\n",
    "# #         \"\"\"\n",
    "# #         MATCH (m:Movie {title: $title})\n",
    "# #         SET m.taglineEmbedding = $embedding\n",
    "# #         \"\"\",\n",
    "# #         params={\"title\": title, \"embedding\": embedding},\n",
    "# #     )\n",
    "\n",
    "# # print(\"Embeddings updated successfully.\")\n",
    "\n",
    "# graph.query(\n",
    "#     \"\"\"\n",
    "#     MATCH (movie:Movie) WHERE movie.tagline IS NOT NULL\n",
    "#     WITH movie, genai.vector.encode(\n",
    "#         movie.tagline, \n",
    "#         \"OpenAI\", \n",
    "#         {\n",
    "#           token: $openAiApiKey,\n",
    "#           endpoint: $openAiEndpoint\n",
    "#         }) AS vector\n",
    "#     CALL db.create.setNodeVectorProperty(movie, \"taglineEmbedding\", vector)\n",
    "#     \"\"\",\n",
    "#     params={\"openAiApiKey\": OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT},\n",
    "# )\n",
    "\n",
    "# question = \"What movies are about love?\"\n",
    "\n",
    "# graph.query(\n",
    "#     \"\"\"\n",
    "#     WITH genai.vector.encode(\n",
    "#         $question, \n",
    "#         \"OpenAI\", \n",
    "#         {\n",
    "#           token: $openAiApiKey,\n",
    "#           endpoint: $openAiEndpoint\n",
    "#         }) AS question_embedding\n",
    "#     CALL db.index.vector.queryNodes(\n",
    "#         'movie_tagline_embeddings', \n",
    "#         $top_k, \n",
    "#         question_embedding\n",
    "#         ) YIELD node AS movie, score\n",
    "#     RETURN movie.title, movie.tagline, score\n",
    "#     \"\"\",\n",
    "#     params={\n",
    "#         \"openAiApiKey\": OPENAI_API_KEY,\n",
    "#         \"openAiEndpoint\": OPENAI_ENDPOINT,\n",
    "#         \"question\": question,\n",
    "#         \"top_k\": 5,\n",
    "#     },\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database purged\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "load_dotenv(override=True)\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\")\n",
    "NEO4J_USERNAME = os.getenv(\"NEO4J_USERNAME\")\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\")\n",
    "NEO4J_DATABASE = os.getenv(\"NEO4J_DATABASE\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_ENDPOINT = os.getenv(\"OPENAI_ENDPOINT\")\n",
    "OPENAI_EMBEDDING_ENDPOINT = os.getenv(\"OPENAI_EMBEDDING_ENDPOINT\")\n",
    "\n",
    "VECTOR_INDEX_NAME = \"form_10k_chunks\"\n",
    "VECTOR_NODE_LABEL = \"Chunk\"\n",
    "VECTOR_SOURCE_PROPERTY = \"text\"\n",
    "VECTOR_EMBEDDING_PROPERTY = \"textEmbedding\"\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE,\n",
    ")\n",
    "\n",
    "graph.query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "for answer in graph.query(\"SHOW CONSTRAINTS;\"):\n",
    "    graph.query(f\"DROP CONSTRAINT `{answer['name']}`;\")\n",
    "\n",
    "for answer in graph.query(\"SHOW INDEXES;\"):\n",
    "    graph.query(f\"DROP INDEX `{answer['name']}`;\")\n",
    "\n",
    "print(\"Database purged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 432\n"
     ]
    }
   ],
   "source": [
    "with open(\"../data/GM_10k/gm-20231231.html\", \"r\") as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "text_lst = soup.find_all(\"div\", style=\"text-align:justify;text-indent:9pt\")\n",
    "text_lst = [text.get_text().encode(\"ascii\", \"ignore\").decode(\"ascii\") for text in text_lst]\n",
    "text_lst = [text for text in text_lst if text]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 2000,\n",
    "    chunk_overlap  = 200,\n",
    ")\n",
    "\n",
    "documents = [Document(page_content=text) for text in text_lst]\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'nodeCount': 432}]\n",
      "[{'id': 4, 'name': 'form_10k_chunks', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'VECTOR', 'entityType': 'NODE', 'labelsOrTypes': ['Chunk'], 'properties': ['textEmbedding'], 'indexProvider': 'vector-2.0', 'owningConstraint': None, 'lastRead': None, 'readCount': None}, {'id': 10, 'name': 'unique_chunk', 'state': 'ONLINE', 'populationPercent': 100.0, 'type': 'RANGE', 'entityType': 'NODE', 'labelsOrTypes': ['Chunk'], 'properties': ['chunkId'], 'indexProvider': 'range-1.0', 'owningConstraint': 'unique_chunk', 'lastRead': None, 'readCount': None}]\n",
      "Node properties:\n",
      "Chunk {textEmbedding: LIST, chunkId: INTEGER, text: STRING, source: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunkId, chunk in enumerate(chunks):\n",
    "    chunkText = chunk.page_content\n",
    "    graph.query(\n",
    "        \"\"\"\n",
    "        MERGE(mergedChunk:Chunk {chunkId: $chunkId})\n",
    "        ON CREATE SET \n",
    "            mergedChunk.text = $chunkText,\n",
    "            mergedChunk.source = $source\n",
    "        RETURN mergedChunk  \n",
    "        \"\"\",\n",
    "        params={\"chunkId\": chunkId,\n",
    "                \"chunkText\": chunkText,\n",
    "                \"source\": \"GM_10k\"},\n",
    "    )\n",
    "\n",
    "graph.query(\n",
    "    \"\"\"\n",
    "    CREATE CONSTRAINT unique_chunk IF NOT EXISTS \n",
    "        FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "result = graph.query(\n",
    "    \"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN count(n) as nodeCount\n",
    "    \"\"\"\n",
    ")\n",
    "print(result)\n",
    "\n",
    "graph.query(\n",
    "    \"\"\"\n",
    "    CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
    "        FOR (c:Chunk) ON (c.textEmbedding) \n",
    "        OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "        }}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "result = graph.query(\n",
    "    \"\"\"\n",
    "    SHOW INDEXES\n",
    "    \"\"\"\n",
    ")\n",
    "print(result)\n",
    "\n",
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "    WITH chunk, genai.vector.encode(\n",
    "      chunk.text, \n",
    "      \"OpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey, \n",
    "        endpoint: $openAiEndpoint\n",
    "      }) AS vector\n",
    "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "    \"\"\", \n",
    "    params={\"openAiApiKey\":OPENAI_API_KEY,\n",
    "            \"openAiEndpoint\": OPENAI_ENDPOINT}\n",
    ")\n",
    "\n",
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9159088134765625, 'text': 'The foundation of GMs business is our Purpose: We pioneer the innovations that move and connect people to what matters. It is why we exist. Our Purpose, growth strategy and culture all help us on our path towards achieving our vision of a world with zero crashes, zero emissions and zero congestion. Our people are our most valuable asset, and we must continue to attract and retain the best talent in the world in order to achieve this vision. As a result, we strive to create a Workplace of Choice to attract, retain and develop top talent by adhering to a responsible employer philosophy, which includes, among other things, commitments to create job opportunities, pay workers fairly, ensure safety and well-being and promote diversity, equity and inclusion (DEI). Fundamental to these commitments are our company values.'}, {'score': 0.88677978515625, 'text': 'Safety and Well-Being  The safety and well-being of our employees is also a critical component of our ability to transform the future of personal mobility. At GM, we pride ourselves on our commitment to live values that return people home safely  Every Person, Every Site, Every Day. Our unwavering commitment to safety is manifested through empowering employees to Speak Up for Safety and the Employee Safety Concern Process. These resources make it easier for salaried, hourly or represented and contract employees to report potential vehicle or workplace safety issues, or to suggest safety related improvements without fear of retaliation. The well-being of our employees is equally as important to entice and stimulate creativity and innovation.'}, {'score': 0.886260986328125, 'text': 'Based on these longstanding values, we have a number of programs and partnerships aimed at enhancing our culture of inclusion throughout the Company. For example, we have 12 voluntary, employee-led resource groups that provide a forum for diverse employees and allies from a variety of different backgrounds to share experiences and contribute to our collective cultural intelligence and growth. Each group also works to attract and retain new talent and offers employees opportunities to support our Companys diversity initiatives within the community.'}, {'score': 0.8860931396484375, 'text': 'General Motors Company was incorporated as a Delaware corporation in 2009. We design, build and sell trucks, crossovers, cars and automobile parts and provide software-enabled services and subscriptions worldwide. Additionally, we are investing in and growing an AV business. We also provide automotive financing services through GM Financial. We analyze the results of our operations through the following segments: GMNA, GMI, Cruise and GM Financial. Cruise is our global segment responsible for the development and commercialization of AV technology. Corporate includes certain centrally recorded income and costs such as interest, income taxes, corporate expenditures and certain revenues and expenses that are not part of a reportable segment. The consolidated financial statements are prepared in conformity with U.S. GAAP. Except for per share amounts or as otherwise specified, amounts presented within tables are stated in millions. Certain columns and rows may not add due to rounding.'}, {'score': 0.8858642578125, 'text': 'The Company maintains technical and organizational safeguards, including employee training, incident response capability reviews and exercises, cybersecurity insurance and business continuity mechanisms for the protection of the Companys assets.  From time to time, the Companys processes are audited and validated by internal and external experts. The Company leverages a third-party cybersecurity program with the goal of minimizing disruption to the Companys business and production operations, strengthening supply chain resilience in response to cyber-related events and supporting the integrity of components and systems used in its products and services.'}, {'score': 0.88568115234375, 'text': \"Develop and Retain Talented People  Today, we compete for talent against other automotive companies and against businesses in other sectors, such as technology. To win and keep top talent, we must provide a workplace culture that encourages employee behaviors aligned with our values, fulfills employees' long-term individual aspirations and provides experiences that make individuals feel valued, included and engaged. In furtherance of this goal, we invest significant resources to retain and develop our talent. In addition to mentoring and networking opportunities, we offer a vast array of career development resources to help develop, grow and enable employees to make the most of their careers at GM. Formal resources include, among other things, the Technical Education Program, which offers our employees an opportunity to complete corporate strategically aligned degrees and certificate programs at leading universities, and our Degreed Learning Platform, which brings forth a variety of external and in-house content in learning pathways and other micro learnings. It is also tied to our GM competency and skills model. Employees in some of our technical roles also have the opportunity to participate in the\"}, {'score': 0.8848419189453125, 'text': 'Diversity, Equity and Inclusion  At GM, we are committed to fostering a culture of diversity, equity and inclusion for our workforce, business partners, customers and communities as we aspire to be the most inclusive company in the world. We believe these strengths will allow us to not only lead the industry but to impact communities around the world as we transition to an all-electric future. This unwavering commitment includes taking steps to ensure that all areas of our business are supportive of a world-class inclusive, equitable and diverse organization. Our ability to meet the needs of a diverse and global customer base is tied closely to the behaviors of the people within our Company, which is why we are committed to fostering a culture that celebrates our differences. This commitment is embraced at all levels of the organization, including our diverse Board of Directors, which is currently made up of almost 50% women (6 out of 13 members) and is more than 30% racially or ethnically diverse (4 out of 13 members).'}, {'score': 0.884033203125, 'text': 'GM continues to align DEI efforts with business objectives, including investing in talent pipelines to support current and future workforce needs, bolstering inclusive and accessible solutions across all key stakeholders and fostering meaningful community partnerships to enable GMs all-electric future. These investments are designed to help increase overall DEI maturity throughout our enterprise, increasing pathways for talent entry and development in the Company and foster partnerships that improve equity inside and outside of GM.'}, {'score': 0.8839111328125, 'text': \"Software & Services  The newly created Software & Services organization, with a presence in Silicon Valley, California and globally, is bringing together all of GM's software capabilities and assets under one team for the first time at GM. The team is developing and implementing an integrated strategy, working closely with the Global Product Development organization and others across the enterprise to deliver an end-to-end integrated software and services strategy that will make the driver experience even more compelling and seamless.\"}, {'score': 0.8834991455078125, 'text': 'To further mitigate the impacts of our worldwide operations on the environment, including climate change, we are supplementing our compliance programs with sustainability efforts focused on reducing operational GHG emissions, water consumption and discharge and operational waste.'}]\n"
     ]
    }
   ],
   "source": [
    "def neo4j_vector_search(question):\n",
    "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
    "  vector_search_query = \"\"\"\n",
    "    WITH genai.vector.encode(\n",
    "      $question, \n",
    "      \"OpenAI\", \n",
    "      {\n",
    "        token: $openAiApiKey,\n",
    "        endpoint: $openAiEndpoint\n",
    "      }) AS question_embedding\n",
    "    CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
    "    RETURN score, node.text AS text\n",
    "  \"\"\"\n",
    "  similar = graph.query(vector_search_query, \n",
    "                     params={\n",
    "                      'question': question, \n",
    "                      'openAiApiKey':OPENAI_API_KEY,\n",
    "                      'openAiEndpoint': OPENAI_ENDPOINT,\n",
    "                      'index_name':VECTOR_INDEX_NAME, \n",
    "                      'top_k': 10}\n",
    "                      )\n",
    "  return similar\n",
    "\n",
    "question = \"What is the company's mission?\"\n",
    "similar = neo4j_vector_search(question)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: How many employees does General Motors have?\n",
      "Answer: General Motors has 164,000 employees.\n",
      "\n",
      "Sources: GM_10k\n"
     ]
    }
   ],
   "source": [
    "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    node_label=VECTOR_NODE_LABEL,\n",
    "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
    "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
    ")\n",
    "\n",
    "retriever = neo4j_vector_store.as_retriever()\n",
    "\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever\n",
    ")\n",
    "\n",
    "question = \"How many employees does General Motors have?\"\n",
    "result = chain({\"question\": question})\n",
    "print(\"Question:\", question)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Sources:\", result['sources'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'form': {'formId': 0, 'source': 'text'}}]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "MERGE (form:Form {formId: 0})\n",
    "    ON CREATE\n",
    "        SET form.formId = 0\n",
    "        SET form.source = $formParam.source\n",
    "RETURN form\n",
    "\"\"\",\n",
    "params={\"formParam\": {\"source\": VECTOR_SOURCE_PROPERTY}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "MATCH (chunk:Chunk)\n",
    "SET chunk.formId = 0\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'size(chunkList)': 432}]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "MATCH (chunk:Chunk)\n",
    "WHERE chunk.formId = $chunkFormId\n",
    "ORDER BY chunk.chunkId ASC\n",
    "WITH collect(chunk) as chunkList\n",
    "    CALL apoc.nodes.link(\n",
    "        chunkList, \n",
    "        \"NEXT\", \n",
    "        {avoidDuplicates: true}\n",
    "    )\n",
    "RETURN size(chunkList)\n",
    "\"\"\",\n",
    "params={\"chunkFormId\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count(newRelationship)': 432}]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "  MATCH (chunk:Chunk), (form:Form)\n",
    "    WHERE chunk.formId = form.formId\n",
    "  MERGE (chunk)-[newRelationship:PART_OF]->(form)\n",
    "  RETURN count(newRelationship)\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Chunk {textEmbedding: LIST, formId: INTEGER, chunkId: INTEGER, text: STRING, source: STRING}\n",
      "Form {formId: INTEGER, source: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Chunk)-[:PART_OF]->(:Form)\n",
      "(:Chunk)-[:NEXT]->(:Chunk)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'c1.chunkId': 0, 'c2.chunkId': 1, 'c3.chunkId': 2},\n",
       " {'c1.chunkId': 1, 'c2.chunkId': 2, 'c3.chunkId': 3},\n",
       " {'c1.chunkId': 2, 'c2.chunkId': 3, 'c3.chunkId': 4},\n",
       " {'c1.chunkId': 3, 'c2.chunkId': 4, 'c3.chunkId': 5},\n",
       " {'c1.chunkId': 4, 'c2.chunkId': 5, 'c3.chunkId': 6},\n",
       " {'c1.chunkId': 5, 'c2.chunkId': 6, 'c3.chunkId': 7},\n",
       " {'c1.chunkId': 6, 'c2.chunkId': 7, 'c3.chunkId': 8},\n",
       " {'c1.chunkId': 7, 'c2.chunkId': 8, 'c3.chunkId': 9},\n",
       " {'c1.chunkId': 8, 'c2.chunkId': 9, 'c3.chunkId': 10},\n",
       " {'c1.chunkId': 9, 'c2.chunkId': 10, 'c3.chunkId': 11}]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH (c1:Chunk)-[:NEXT]->(c2:Chunk)-[:NEXT]->(c3:Chunk)\n",
    "    ORDER BY c1.chunkId ASC\n",
    "    LIMIT 10\n",
    "    RETURN c1.chunkId, c2.chunkId, c3.chunkId\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'c1.chunkId': 0, 'c2.chunkId': 0, 'c3.chunkId': 0, 'length(window)': 0},\n",
       " {'c1.chunkId': 0, 'c2.chunkId': 0, 'c3.chunkId': 1, 'length(window)': 1},\n",
       " {'c1.chunkId': 0, 'c2.chunkId': 1, 'c3.chunkId': 1, 'length(window)': 1},\n",
       " {'c1.chunkId': 0, 'c2.chunkId': 1, 'c3.chunkId': 2, 'length(window)': 2},\n",
       " {'c1.chunkId': 1, 'c2.chunkId': 1, 'c3.chunkId': 1, 'length(window)': 0},\n",
       " {'c1.chunkId': 1, 'c2.chunkId': 1, 'c3.chunkId': 2, 'length(window)': 1},\n",
       " {'c1.chunkId': 1, 'c2.chunkId': 2, 'c3.chunkId': 2, 'length(window)': 1},\n",
       " {'c1.chunkId': 1, 'c2.chunkId': 2, 'c3.chunkId': 3, 'length(window)': 2},\n",
       " {'c1.chunkId': 2, 'c2.chunkId': 2, 'c3.chunkId': 2, 'length(window)': 0},\n",
       " {'c1.chunkId': 2, 'c2.chunkId': 2, 'c3.chunkId': 3, 'length(window)': 1}]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH window = (c1:Chunk)-[:NEXT*0..1]->(c2:Chunk)-[:NEXT*0..1]->(c3:Chunk)\n",
    "    ORDER BY c1.chunkId ASC\n",
    "    LIMIT 10\n",
    "    RETURN c1.chunkId, c2.chunkId, c3.chunkId, length(window)\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'c1.chunkId': 251,\n",
       "  'c2.chunkId': 252,\n",
       "  'c3.chunkId': 253,\n",
       "  'length(window)': 2}]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH window = (c1:Chunk)-[:NEXT*0..1]->(c2:Chunk)-[:NEXT*0..1]->(c3:Chunk)\n",
    "    ORDER BY length(window) DESC\n",
    "    LIMIT 1\n",
    "    RETURN c1.chunkId, c2.chunkId, c3.chunkId, length(window)\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM meets the demands of customers in North America and outside North America with vehicles developed, manufactured, and/or marketed under various brands. They also provide automotive financing services through GM Financial. BMW is considered to build better cars than GM.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieval_query_extra_text = \"\"\"\n",
    "WITH node, score, \"BMW builds better cars than GM. \" as extraText\n",
    "RETURN extraText + \"\\n\" + node.text as text, score, node {.source} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "vector_store_extra_text = Neo4jVector.from_existing_index(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    text_node_property=VECTOR_SOURCE_PROPERTY,\n",
    "    retrieval_query=retrieval_query_extra_text,\n",
    ")\n",
    "\n",
    "retriever_extra_text = vector_store_extra_text.as_retriever()\n",
    "\n",
    "chain_extra_text = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever_extra_text\n",
    ")\n",
    "\n",
    "result = chain_extra_text({\"question\": \"What does GM do and how do their products compare to BMW?\"})\n",
    "print(result[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following table reconciles our effective tax rate under U.S. GAAP to ETR-adjusted: \n",
      " We define return on equity (ROE) as Net income attributable to stockholders for the trailing four quarters divided by average equity for the same period. Management uses average equity to provide comparable amounts in the calculation of ROE. The following table summarizes the calculation of ROE (dollars in billions): \n",
      " We caution readers not to place undue reliance on forward-looking statements. Forward-looking statements speak only as of the date they are made, and we undertake no obligation to update publicly or otherwise revise any forward-looking statements, whether as a result of new information, future events or other factors, except where we are expressly required to do so by law.\n"
     ]
    }
   ],
   "source": [
    "result = graph.query(\n",
    "    \"\"\"\n",
    "    MATCH window=(:Chunk)-[:NEXT*0..1]->(node)-[:NEXT*0..1]->(:Chunk)\n",
    "    WITH window as longestWindow \n",
    "    ORDER BY length(window) DESC LIMIT 1\n",
    "    WITH nodes(longestWindow) as chunkList\n",
    "    UNWIND chunkList as chunkRows\n",
    "    WITH collect(chunkRows.text) as textList\n",
    "    RETURN apoc.text.join(textList, \" \\n \") as text\n",
    "\"\"\"\n",
    ")\n",
    "print(result[0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GM produces trucks, crossovers, cars, and automobile parts that are marketed through retail dealers in North America and distributors and dealers outside of North America. They also provide automotive financing services through GM Financial. GM's products are developed, manufactured, and/or marketed under various brands such as Buick, Cadillac, Chevrolet, and GMC. In comparison to BMW, GM offers a wider range of vehicles across different brands and has a focus on meeting the demands of customers in North America and other countries. BMW, on the other hand, is a German multinational company that primarily focuses on luxury vehicles and motorcycles under the BMW, Mini, and Rolls-Royce brands.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieval_query_extra_text = \"\"\"\n",
    "  MATCH window=\n",
    "      (:Chunk)-[:NEXT*0..1]->(node)-[:NEXT*0..1]->(:Chunk)\n",
    "  WITH node, score, window as longestWindow \n",
    "    ORDER BY length(window) DESC LIMIT 1\n",
    "  WITH nodes(longestWindow) as chunkList, node, score\n",
    "    UNWIND chunkList as chunkRows\n",
    "  WITH collect(chunkRows.text) as textList, node, score\n",
    "  RETURN apoc.text.join(textList, \" \\n \") as text,\n",
    "      score,\n",
    "      node {.source} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "vector_store_extra_text = Neo4jVector.from_existing_index(\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    "    database=NEO4J_DATABASE,\n",
    "    index_name=VECTOR_INDEX_NAME,\n",
    "    text_node_property=VECTOR_SOURCE_PROPERTY,\n",
    "    retrieval_query=retrieval_query_extra_text,\n",
    ")\n",
    "\n",
    "retriever_extra_text = vector_store_extra_text.as_retriever()\n",
    "\n",
    "chain_extra_text = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    ChatOpenAI(temperature=0), \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever_extra_text\n",
    ")\n",
    "\n",
    "result = chain_extra_text({\"question\": \"What does GM do and how do their products compare to BMW?\"})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node properties:\n",
      "Chunk {textEmbedding: LIST, formId: INTEGER, chunkId: INTEGER, text: STRING, source: STRING}\n",
      "Form {formId: INTEGER, source: STRING}\n",
      "Relationship properties:\n",
      "\n",
      "The relationships:\n",
      "(:Chunk)-[:PART_OF]->(:Form)\n",
      "(:Chunk)-[:NEXT]->(:Chunk)\n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nextCount': 431}]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH (:Chunk)-[next:NEXT]->(:Chunk)\n",
    "    RETURN COUNT(next) as nextCount\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relationCount': 432}]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH (:Chunk)-[relation]->(:Form)\n",
    "    RETURN COUNT(relation) as relationCount\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'relationCount': 863}]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "    \"\"\"\n",
    "    MATCH ()-[relation]->()\n",
    "    RETURN COUNT(relation) as relationCount\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "language_processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
