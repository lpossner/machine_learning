{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "    f1_score, roc_auc_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Titanic/train.csv')\n",
    "df_train = pd.read_csv('../data/Titanic/test.csv')\n",
    "passenger_id = df_train['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnecessary_columns = ['PassengerId', 'Name', 'Ticket']\n",
    "unnecessary_columns = ['PassengerId', 'Ticket']\n",
    "df = df.drop(columns=unnecessary_columns)\n",
    "df_train = df_train.drop(columns=unnecessary_columns)\n",
    "\n",
    "target_column = 'Survived'\n",
    "\n",
    "X = df.drop(columns=[target_column])\n",
    "y = df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['MarriedFemale'] = X['Name'].apply(lambda x: 'Mrs' in x)\n",
    "X = X.drop(columns=['Name'])\n",
    "\n",
    "df_train['MarriedFemale'] = df_train['Name'].apply(lambda x: 'Mrs' in x)\n",
    "df_train = df_train.drop(columns=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cabin_level(cabin):\n",
    "    if type(cabin) is not str:\n",
    "        return None\n",
    "    level = cabin.split(' ')[0][0]\n",
    "    return level\n",
    "\n",
    "\n",
    "def extract_cabin_count(cabin):\n",
    "    if type(cabin) is not str:\n",
    "        return None\n",
    "    cabins = cabin.split(' ')\n",
    "    return len(cabins)\n",
    "\n",
    "X['CabinLevel'] = X['Cabin'].apply(extract_cabin_level)\n",
    "X['CabinCount'] = X['Cabin'].apply(extract_cabin_count)\n",
    "df_train['CabinLevel'] = df_train['Cabin'].apply(extract_cabin_level)\n",
    "df_train['CabinCount'] = df_train['Cabin'].apply(extract_cabin_count)\n",
    "\n",
    "X = X.drop(columns=['Cabin'])\n",
    "df_train = df_train.drop(columns=['Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   Pclass         891 non-null    category\n",
      " 1   Sex            891 non-null    category\n",
      " 2   Age            714 non-null    float64 \n",
      " 3   SibSp          891 non-null    category\n",
      " 4   Parch          891 non-null    category\n",
      " 5   Fare           891 non-null    float64 \n",
      " 6   Embarked       889 non-null    category\n",
      " 7   MarriedFemale  891 non-null    category\n",
      " 8   CabinLevel     204 non-null    category\n",
      " 9   CabinCount     204 non-null    category\n",
      "dtypes: category(8), float64(2)\n",
      "memory usage: 22.7 KB\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['Pclass', 'Sex', 'SibSp', 'Parch', 'CabinLevel', 'CabinCount', 'Embarked', 'MarriedFemale']\n",
    "# categorical_columns = ['Pclass', 'Sex', 'SibSp', 'Parch', 'CabinLevel', 'CabinCount', 'Embarked']\n",
    "numerical_columns = ['Age', 'Fare']\n",
    "\n",
    "X[categorical_columns] = X[categorical_columns].astype('category')\n",
    "X[numerical_columns] = X[numerical_columns].astype('float')\n",
    "df_train[categorical_columns] = df_train[categorical_columns].astype('category')\n",
    "df_train[numerical_columns] = df_train[numerical_columns].astype('float')\n",
    "\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass            0.000000\n",
       "Sex               0.000000\n",
       "Age              19.865320\n",
       "SibSp             0.000000\n",
       "Parch             0.000000\n",
       "Fare              0.000000\n",
       "Embarked          0.224467\n",
       "MarriedFemale     0.000000\n",
       "CabinLevel       77.104377\n",
       "CabinCount       77.104377\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum(axis=0) / len(X) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['CabinLevel', 'CabinCount'])\n",
    "df_train = df_train.drop(columns=['CabinLevel', 'CabinCount'])\n",
    "categorical_columns.remove('CabinLevel')\n",
    "categorical_columns.remove('CabinCount')\n",
    "\n",
    "for column in categorical_columns:\n",
    "    X[column] = X[column].fillna(X[column].mode().iloc[0])\n",
    "    df_train[column] = df_train[column].fillna(df_train[column].mode().iloc[0])\n",
    "for column in numerical_columns:\n",
    "    X[column] = X[column].fillna(X[column].median())\n",
    "    df_train[column] = df_train[column].fillna(df_train[column].median())\n",
    "\n",
    "# # Impute Age\n",
    "# column = 'Age'\n",
    "\n",
    "# nan_mask = X[column].isna()\n",
    "# X_imp_fit = X[~nan_mask].drop(columns=[column])\n",
    "# y_imp_fit = X[~nan_mask][column]\n",
    "\n",
    "# imputer = XGBRegressor(enable_categorical=True)\n",
    "# imputer.fit(X_imp_fit, y_imp_fit)\n",
    "# X_imp_pred = X[nan_mask].drop(columns=[column])\n",
    "# y_fill = imputer.predict(X_imp_pred)\n",
    "\n",
    "# X.loc[nan_mask, column] = y_fill\n",
    "\n",
    "# # Impute Embarked\n",
    "# column = 'Embarked'\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# nan_mask = X[column].isna()\n",
    "# X_imp_fit = X[~nan_mask].drop(columns=[column])\n",
    "# y_imp_fit = encoder.fit_transform(X[~nan_mask][[column]])\n",
    "\n",
    "# imputer = XGBClassifier(enable_categorical=True)\n",
    "# imputer.fit(X_imp_fit, y_imp_fit)\n",
    "# X_imp_pred = X[nan_mask].drop(columns=[column])\n",
    "# y_fill = encoder.inverse_transform(imputer.predict(X_imp_pred)[:, np.newaxis])\n",
    "\n",
    "# X.loc[nan_mask, column] = y_fill\n",
    "\n",
    "# # Impute CabinLevel\n",
    "# column = 'CabinLevel'\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# nan_mask = X[column].isna()\n",
    "# X_imp_fit = X[~nan_mask].drop(columns=[column])\n",
    "# y_imp_fit = encoder.fit_transform(X[~nan_mask][[column]])\n",
    "\n",
    "# imputer = XGBClassifier(enable_categorical=True)\n",
    "# imputer.fit(X_imp_fit, y_imp_fit)\n",
    "# X_imp_pred = X[nan_mask].drop(columns=[column])\n",
    "# y_fill = encoder.inverse_transform(imputer.predict(X_imp_pred)[:, np.newaxis])\n",
    "\n",
    "# X.loc[nan_mask, column] = y_fill\n",
    "\n",
    "# # Impute CabinCount\n",
    "# column = 'CabinCount'\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# nan_mask = X[column].isna()\n",
    "# X_imp_fit = X[~nan_mask].drop(columns=[column])\n",
    "# y_imp_fit = encoder.fit_transform(X[~nan_mask][[column]])\n",
    "\n",
    "# imputer = XGBClassifier(enable_categorical=True)\n",
    "# imputer.fit(X_imp_fit, y_imp_fit)\n",
    "# X_imp_pred = X[nan_mask].drop(columns=[column])\n",
    "# y_fill = encoder.inverse_transform(imputer.predict(X_imp_pred)[:, np.newaxis])\n",
    "\n",
    "# X.loc[nan_mask, column] = y_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[categorical_columns] = X[categorical_columns].astype('category')\n",
    "X[numerical_columns] = X[numerical_columns].astype('float')\n",
    "\n",
    "df_train[categorical_columns] = df_train[categorical_columns].astype('category')\n",
    "df_train[numerical_columns] = df_train[numerical_columns].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass           0.0\n",
       "Sex              0.0\n",
       "Age              0.0\n",
       "SibSp            0.0\n",
       "Parch            0.0\n",
       "Fare             0.0\n",
       "Embarked         0.0\n",
       "MarriedFemale    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum(axis=0) / len(X) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   Pclass         891 non-null    category\n",
      " 1   Sex            891 non-null    category\n",
      " 2   Age            891 non-null    float64 \n",
      " 3   SibSp          891 non-null    category\n",
      " 4   Parch          891 non-null    category\n",
      " 5   Fare           891 non-null    float64 \n",
      " 6   Embarked       891 non-null    category\n",
      " 7   MarriedFemale  891 non-null    category\n",
      "dtypes: category(6), float64(2)\n",
      "memory usage: 20.4 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9629629629629629\n",
      "Presicion: 0.9667673716012085\n",
      "Recall: 0.935672514619883\n",
      "F1: 0.950965824665676\n",
      "ROC AUC: 0.9578180423736937\n",
      "Confusion Matrix:\n",
      "[[538  11]\n",
      " [ 22 320]]\n"
     ]
    }
   ],
   "source": [
    "# Split dataset in train and test data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = X, X, y, y\n",
    "\n",
    "# Train classifier and predict data \n",
    "clf = XGBClassifier(enable_categorical=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy:{accuracy}')\n",
    "print(f'Presicion: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "print('Confusion Matrix:')\n",
    "print(f'{confusion_mat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.concat([passenger_id, pd.DataFrame(y_pred, columns=['Survived'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('../results/Titanic/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
