{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy.stats import fisher_exact, chi2_contingency, skew, kurtosis\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, \\\n",
    "    OrdinalEncoder, PowerTransformer, QuantileTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "    f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_classif, \\\n",
    "    mutual_info_regression\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/DontGetKicked/training.csv')\n",
    "df_train = pd.read_csv('../data/DontGetKicked/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify columns into categorical and numerical\n",
    "categorical_columns = [\n",
    "    'Auction', 'Make', 'Model', 'Trim', 'SubModel', 'Color', \n",
    "    'VehYear', 'Transmission', 'WheelType', 'Nationality', 'Size', \n",
    "    'TopThreeAmericanName', 'PRIMEUNIT', 'AUCGUART', 'VNST',\n",
    "    'WheelTypeID', 'VNZIP1', 'IsOnlineSale', 'PurchDate'\n",
    "]\n",
    "df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "df_train[categorical_columns] = df_train[categorical_columns].astype('category')\n",
    "numerical_columns = list(set(df.columns) - set(categorical_columns))\n",
    "target_column =  'IsBadBuy'\n",
    "numerical_columns.remove(target_column)\n",
    "df[numerical_columns] = df[numerical_columns].astype('float')\n",
    "df_train[numerical_columns] = df_train[numerical_columns].astype('float')\n",
    "\n",
    "\n",
    "# Define helper functions\n",
    "def drop_columns(df, columns):\n",
    "    df = df.drop(columns=columns)\n",
    "    for column in columns:\n",
    "        if column in categorical_columns:\n",
    "            categorical_columns.remove(column)\n",
    "        if column in numerical_columns:\n",
    "            numerical_columns.remove(column)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_categorical_column(df, column, values):\n",
    "    df[column] = values\n",
    "    df[column] = df[column].astype('category')\n",
    "    categorical_columns.append(column)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_numerical_column(df, column, values):\n",
    "    df[column] = values\n",
    "    df[column] = df[column].astype('float')\n",
    "    numerical_columns.append(column)\n",
    "    return df\n",
    "\n",
    "\n",
    "def plot_distributions(df, columns):\n",
    "    num_columns = len(columns)\n",
    "    columns_per_row = 2\n",
    "    rows = (num_columns + columns_per_row - 1) // columns_per_row\n",
    "    fig, axes = plt.subplots(rows, columns_per_row, figsize=(12, rows * 4))\n",
    "    axes = axes.flatten()\n",
    "    for index, column in enumerate(df[columns].columns):\n",
    "        sns.histplot(df[column], kde=True, ax=axes[index])\n",
    "        axes[index].set_title(f'Distribution of {column}')\n",
    "    for del_index in range(index + 1, len(axes)):\n",
    "        fig.delaxes(axes[del_index])\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def nmad(df):\n",
    "    df_clean = df.dropna()\n",
    "    median = np.median(df_clean)\n",
    "    return np.median(np.abs(df_clean - median)) / median\n",
    "\n",
    "\n",
    "def cov(df):\n",
    "    df_clean = df.dropna()\n",
    "    return np.std(df_clean) / np.mean(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72983 entries, 0 to 72982\n",
      "Data columns (total 26 columns):\n",
      " #   Column                             Non-Null Count  Dtype   \n",
      "---  ------                             --------------  -----   \n",
      " 0   IsBadBuy                           72983 non-null  int64   \n",
      " 1   Auction                            72983 non-null  category\n",
      " 2   VehicleAge                         72983 non-null  float64 \n",
      " 3   Make                               72983 non-null  category\n",
      " 4   Color                              72975 non-null  category\n",
      " 5   Transmission                       72974 non-null  category\n",
      " 6   WheelType                          69809 non-null  category\n",
      " 7   VehOdo                             72983 non-null  float64 \n",
      " 8   Nationality                        72978 non-null  category\n",
      " 9   Size                               72978 non-null  category\n",
      " 10  TopThreeAmericanName               72978 non-null  category\n",
      " 11  MMRAcquisitionAuctionAveragePrice  72965 non-null  float64 \n",
      " 12  MMRAcquisitionAuctionCleanPrice    72965 non-null  float64 \n",
      " 13  MMRAcquisitionRetailAveragePrice   72965 non-null  float64 \n",
      " 14  MMRAcquisitonRetailCleanPrice      72965 non-null  float64 \n",
      " 15  MMRCurrentAuctionAveragePrice      72668 non-null  float64 \n",
      " 16  MMRCurrentAuctionCleanPrice        72668 non-null  float64 \n",
      " 17  MMRCurrentRetailAveragePrice       72668 non-null  float64 \n",
      " 18  MMRCurrentRetailCleanPrice         72668 non-null  float64 \n",
      " 19  PRIMEUNIT                          3419 non-null   category\n",
      " 20  AUCGUART                           3419 non-null   category\n",
      " 21  VNST                               72983 non-null  category\n",
      " 22  VehBCost                           72983 non-null  float64 \n",
      " 23  IsOnlineSale                       72983 non-null  category\n",
      " 24  WarrantyCost                       72983 non-null  float64 \n",
      " 25  PurchMonth                         72983 non-null  category\n",
      "dtypes: category(13), float64(12), int64(1)\n",
      "memory usage: 8.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "unnecessary_columns = ['RefId', 'WheelTypeID', 'BYRNO',\n",
    "             'VNZIP1', 'SubModel', 'Trim', 'Model',\n",
    "             'VehYear'\n",
    "             ]    \n",
    "df = drop_columns(df=df, columns=unnecessary_columns)\n",
    "unnecessary_columns.remove('RefId')\n",
    "df_train = drop_columns(df=df_train, columns=unnecessary_columns)\n",
    "unnecessary_columns.append('RefId')\n",
    "\n",
    "# Extract month from purchase date string\n",
    "purchase_month = df['PurchDate'].apply(lambda x: x.split('/')[0])\n",
    "df = add_categorical_column(df=df, column='PurchMonth', values=purchase_month)\n",
    "df = drop_columns(df=df, columns=['PurchDate'])\n",
    "\n",
    "purchase_month = df_train['PurchDate'].apply(lambda x: x.split('/')[0])\n",
    "df_train = add_categorical_column(df=df_train, column='PurchMonth', values=purchase_month)\n",
    "df_train = drop_columns(df=df_train, columns=['PurchDate'])\n",
    "\n",
    "# Convert wheel type to upper case\n",
    "df['WheelType'] = df['WheelType'].apply(lambda x: x.upper())\n",
    "df_train['WheelType'] = df_train['WheelType'].apply(lambda x: x.upper())\n",
    "\n",
    "# Show remaining columns\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    72164.000000\n",
      "mean      6174.908306\n",
      "std       2388.317304\n",
      "min        369.000000\n",
      "25%       4312.000000\n",
      "50%       6088.000000\n",
      "75%       7745.000000\n",
      "max      35722.000000\n",
      "Name: MMRCurrentAuctionAveragePrice, dtype: float64\n",
      "count     72983.000000\n",
      "mean      71499.995917\n",
      "std       14578.913128\n",
      "min        4825.000000\n",
      "25%       61837.000000\n",
      "50%       73361.000000\n",
      "75%       82436.000000\n",
      "max      115717.000000\n",
      "Name: VehOdo, dtype: float64\n",
      "count    72137.000000\n",
      "mean      8594.564648\n",
      "std       3039.447835\n",
      "min       1455.000000\n",
      "25%       6363.000000\n",
      "50%       8483.000000\n",
      "75%      10675.000000\n",
      "max      39080.000000\n",
      "Name: MMRAcquisitionRetailAveragePrice, dtype: float64\n",
      "count    72164.000000\n",
      "mean      8837.013788\n",
      "std       3012.893729\n",
      "min        899.000000\n",
      "25%       6587.750000\n",
      "50%       8756.000000\n",
      "75%      10921.000000\n",
      "max      39080.000000\n",
      "Name: MMRCurrentRetailAveragePrice, dtype: float64\n",
      "count    72164.000000\n",
      "mean     10216.241616\n",
      "std       3210.984266\n",
      "min       1034.000000\n",
      "25%       7839.750000\n",
      "50%      10126.000000\n",
      "75%      12323.500000\n",
      "max      41062.000000\n",
      "Name: MMRCurrentRetailCleanPrice, dtype: float64\n",
      "count    72981.000000\n",
      "mean      6731.115687\n",
      "std       1767.531058\n",
      "min       1400.000000\n",
      "25%       5435.000000\n",
      "50%       6700.000000\n",
      "75%       7900.000000\n",
      "max      45469.000000\n",
      "Name: VehBCost, dtype: float64\n",
      "count    72983.000000\n",
      "mean         4.176644\n",
      "std          1.712210\n",
      "min          0.000000\n",
      "25%          3.000000\n",
      "50%          4.000000\n",
      "75%          5.000000\n",
      "max          9.000000\n",
      "Name: VehicleAge, dtype: float64\n",
      "count    72137.000000\n",
      "mean      6199.257815\n",
      "std       2386.392262\n",
      "min        884.000000\n",
      "25%       4338.000000\n",
      "50%       6138.000000\n",
      "75%       7785.000000\n",
      "max      35722.000000\n",
      "Name: MMRAcquisitionAuctionAveragePrice, dtype: float64\n",
      "count    72164.000000\n",
      "mean      7442.297281\n",
      "std       2623.394815\n",
      "min        494.000000\n",
      "25%       5465.000000\n",
      "50%       7339.000000\n",
      "75%       9024.000000\n",
      "max      36859.000000\n",
      "Name: MMRCurrentAuctionCleanPrice, dtype: float64\n",
      "count    72137.000000\n",
      "mean      7458.269986\n",
      "std       2620.271213\n",
      "min       1076.000000\n",
      "25%       5479.000000\n",
      "50%       7354.000000\n",
      "75%       9044.000000\n",
      "max      36859.000000\n",
      "Name: MMRAcquisitionAuctionCleanPrice, dtype: float64\n",
      "count    72983.000000\n",
      "mean      1276.580985\n",
      "std        598.846788\n",
      "min        462.000000\n",
      "25%        837.000000\n",
      "50%       1155.000000\n",
      "75%       1623.000000\n",
      "max       7498.000000\n",
      "Name: WarrantyCost, dtype: float64\n",
      "count    72137.000000\n",
      "mean      9963.998766\n",
      "std       3235.506626\n",
      "min       1662.000000\n",
      "25%       7561.000000\n",
      "50%       9837.000000\n",
      "75%      12115.000000\n",
      "max      41482.000000\n",
      "Name: MMRAcquisitonRetailCleanPrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define sensible value ranges and mark out-of-range-values as missing\n",
    "numerical_column_ranges = {\n",
    "    'VehicleAge': (0, 30),\n",
    "    'VehOdo': (0, 120000),\n",
    "    'VehBCost': (1000, 46000),\n",
    "    'WarrantyCost': (400, 8000),\n",
    "    'MMRAcquisitionAuctionAveragePrice': (800, 46000),\n",
    "    'MMRAcquisitionAuctionCleanPrice': (1000, 46000),\n",
    "    'MMRAcquisitionRetailAveragePrice': (1000, 46000),\n",
    "    'MMRAcquisitonRetailCleanPrice': (1000, 46000),\n",
    "    'MMRCurrentAuctionAveragePrice': (300, 46000),\n",
    "    'MMRCurrentAuctionCleanPrice': (400, 46000),\n",
    "    'MMRCurrentRetailAveragePrice': (800, 46000),\n",
    "    'MMRCurrentRetailCleanPrice': (1000, 46000)\n",
    "}\n",
    "for column, (min_value, max_value) in numerical_column_ranges.items():\n",
    "    df[column] = df[column].apply(lambda x: x if min_value <= x <= max_value else None)\n",
    "for column, (min_value, max_value) in numerical_column_ranges.items():\n",
    "    df_train[column] = df_train[column].apply(lambda x: x if min_value <= x <= max_value else None)\n",
    "\n",
    "# Drop columns with little variation\n",
    "mask = df[numerical_columns].apply(nmad) < 0.1\n",
    "columns = mask[mask].index.to_list()\n",
    "df = drop_columns(df=df, columns=columns)\n",
    "df_train = drop_columns(df=df_train, columns=columns)\n",
    "\n",
    "# Show column stats\n",
    "for column in numerical_columns:\n",
    "    print(df[column].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auction\n",
      "MANHEIM    41043\n",
      "OTHER      17501\n",
      "ADESA      14439\n",
      "Name: count, dtype: int64\n",
      "Make\n",
      "CHEVROLET     17248\n",
      "DODGE         12912\n",
      "FORD          11305\n",
      "CHRYSLER       8844\n",
      "PONTIAC        4258\n",
      "OTHER          2835\n",
      "KIA            2484\n",
      "SATURN         2163\n",
      "NISSAN         2085\n",
      "HYUNDAI        1811\n",
      "JEEP           1644\n",
      "SUZUKI         1328\n",
      "TOYOTA         1144\n",
      "MITSUBISHI     1030\n",
      "MAZDA           979\n",
      "MERCURY         913\n",
      "Name: count, dtype: int64\n",
      "Color\n",
      "SILVER    14875\n",
      "WHITE     12123\n",
      "BLUE      10347\n",
      "GREY       7887\n",
      "BLACK      7627\n",
      "RED        6257\n",
      "GOLD       5231\n",
      "GREEN      3194\n",
      "MAROON     2046\n",
      "OTHER      1710\n",
      "BEIGE      1584\n",
      "Name: count, dtype: int64\n",
      "Transmission\n",
      "AUTO      70398\n",
      "MANUAL     2576\n",
      "Name: count, dtype: int64\n",
      "WheelType\n",
      "ALLOY      36050\n",
      "COVERS     33004\n",
      "SPECIAL      755\n",
      "Name: count, dtype: int64\n",
      "Nationality\n",
      "AMERICAN          61028\n",
      "OTHER ASIAN        8033\n",
      "TOP LINE ASIAN     3722\n",
      "Name: count, dtype: int64\n",
      "Size\n",
      "MEDIUM         30785\n",
      "LARGE           8850\n",
      "MEDIUM SUV      8090\n",
      "COMPACT         7205\n",
      "VAN             5854\n",
      "LARGE TRUCK     3170\n",
      "SMALL SUV       2276\n",
      "SPECIALTY       1915\n",
      "CROSSOVER       1759\n",
      "LARGE SUV       1433\n",
      "SMALL TRUCK      864\n",
      "SPORTS           777\n",
      "Name: count, dtype: int64\n",
      "TopThreeAmericanName\n",
      "GM          25314\n",
      "CHRYSLER    23399\n",
      "FORD        12315\n",
      "OTHER       11950\n",
      "Name: count, dtype: int64\n",
      "VNST\n",
      "TX       13596\n",
      "FL       10447\n",
      "CA        7095\n",
      "NC        7042\n",
      "AZ        6174\n",
      "OTHER     5448\n",
      "CO        4998\n",
      "SC        4280\n",
      "OK        3594\n",
      "GA        2450\n",
      "TN        1764\n",
      "VA        1662\n",
      "MD        1158\n",
      "UT         875\n",
      "PA         847\n",
      "OH         795\n",
      "MO         758\n",
      "Name: count, dtype: int64\n",
      "IsOnlineSale\n",
      "0    71138\n",
      "1     1845\n",
      "Name: count, dtype: int64\n",
      "PurchMonth\n",
      "10    7178\n",
      "2     6839\n",
      "11    6675\n",
      "9     6511\n",
      "3     6257\n",
      "8     6139\n",
      "4     5935\n",
      "7     5876\n",
      "5     5760\n",
      "6     5675\n",
      "12    5368\n",
      "1     4770\n",
      "Name: count, dtype: int64\n",
      "PurchMonth\n",
      "10    7178\n",
      "2     6839\n",
      "11    6675\n",
      "9     6511\n",
      "3     6257\n",
      "8     6139\n",
      "4     5935\n",
      "7     5876\n",
      "5     5760\n",
      "6     5675\n",
      "12    5368\n",
      "1     4770\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace non-sensible values\n",
    "df['Make'] = df['Make'].astype('object').replace({'TOYOTA SCION': 'SCION'}).astype('category')\n",
    "df['Transmission'] = df['Transmission'].astype('object').replace({'Manual': 'MANUAL'}).astype('category')\n",
    "df['Color'] = df['Color'].astype('object').replace({'NOT AVAIL': None}).astype('category')\n",
    "\n",
    "df_train['Make'] = df_train['Make'].astype('object').replace({'TOYOTA SCION': 'SCION'}).astype('category')\n",
    "df_train['Transmission'] = df_train['Transmission'].astype('object').replace({'Manual': 'MANUAL'}).astype('category')\n",
    "df_train['Color'] = df_train['Color'].astype('object').replace({'NOT AVAIL': None}).astype('category')\n",
    "\n",
    "# Replace rare values\n",
    "for column in categorical_columns:\n",
    "    # Categorize as 'OTHERS'\n",
    "    value_counts = df[column].value_counts()\n",
    "    proba = value_counts / value_counts.sum()\n",
    "    mask = proba <= 0.01\n",
    "    replace_dict = {key: 'OTHER' for key in mask[mask].reset_index().iloc[:, 0].to_list()}\n",
    "    df[column] = df[column].astype('object').replace(replace_dict).astype('category')\n",
    "    df_train[column] = df_train[column].astype('object').replace(replace_dict).astype('category')\n",
    "    # If frequency of 'OTHERS' is too low, mark as missing\n",
    "    num_other = len(df.loc[df[column] == 'OTHER', column])\n",
    "    if num_other / len(df[column]) < 0.01:\n",
    "        df[column] = df[column].astype('object').replace({'OTHER': None}).astype('category')\n",
    "        df_train[column] = df_train[column].astype('object').replace({'OTHER': None}).astype('category')\n",
    "\n",
    "# Drop columns with little variation\n",
    "for column in categorical_columns:\n",
    "    value_counts = df[column].value_counts()\n",
    "    proba = value_counts / value_counts.sum()\n",
    "    if (proba > 0.99).any():\n",
    "        df = drop_columns(df=df, columns=[column])\n",
    "        df_train = drop_columns(df=df_train, columns=[column])\n",
    "\n",
    "# Drop columns with too many missing values, if not correlated with target\n",
    "prob_na = df[categorical_columns].isna().sum() / len(df)\n",
    "mask = prob_na > 0.2\n",
    "na_columns = mask[mask].reset_index().iloc[:, 0].to_list()\n",
    "for column in na_columns:\n",
    "    # p_value = chi2_contingency(pd.crosstab(df[column], df[target_column])).pvalue\n",
    "    p_value = fisher_exact(pd.crosstab(df[column], df[target_column])).pvalue\n",
    "    if p_value > 0.01:\n",
    "        df = drop_columns(df=df, columns=[column])\n",
    "        df_train = drop_columns(df=df_train, columns=[column])\n",
    "\n",
    "# Show column stats\n",
    "for column in categorical_columns:\n",
    "    print(df[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for outliers\n",
    "# # Copy data frame\n",
    "# df_iso = df.drop(columns=[target_column]).copy()\n",
    "\n",
    "# # Replace missing values\n",
    "# for column in categorical_columns:\n",
    "#     df_iso[column] = df_iso[column].fillna(df_iso[column].mode().iloc[0])\n",
    "# for column in numerical_columns:\n",
    "#     df_iso[column] = df_iso[column].fillna(df_iso[column].median())\n",
    "\n",
    "# # Encode categorical values\n",
    "# one_hot_encoder = OneHotEncoder(drop='first', handle_unknown='ignore', sparse_output=False)\n",
    "# one_hot_encoded = one_hot_encoder.fit_transform(df_iso[categorical_columns])\n",
    "# df_iso = pd.concat([pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names_out()), df_iso[numerical_columns].reset_index(drop=True)], axis=1) \n",
    "\n",
    "# # Scale values\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(df_iso)\n",
    "\n",
    "# # Check for outliers using isolation forest\n",
    "# clf = IsolationForest()\n",
    "# outliers = clf.fit_predict(X)\n",
    "\n",
    "# # Show ratio of outliers\n",
    "# print((outliers == -1).sum() / outliers.shape[0] * 100)\n",
    "\n",
    "# # Drop outliers\n",
    "# df = df.drop(df[outliers == -1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show ratio of missing values\n",
    "# print(df.isna().any(axis=1).sum() / len(df) * 100)\n",
    "\n",
    "# # Impute missing values\n",
    "# categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "# df[categorical_columns] = categorical_imputer.fit_transform(df[categorical_columns])\n",
    "# numerical_imputer = SimpleImputer(strategy='median')\n",
    "# df[numerical_columns] = numerical_imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "# # Convert to categorical and float\n",
    "# df[categorical_columns] = df[categorical_columns].astype('category')\n",
    "# df[numerical_columns] = df[numerical_columns].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute mutual information for all combinations of numerical columns\n",
    "# column_combinations = list(combinations(numerical_columns, 2))\n",
    "# mutual_info_scores = [mutual_info_regression(df[[column_1]].values, df[[column_2]].values.squeeze()) for column_1, column_2 in column_combinations]\n",
    "# # Sort list descending\n",
    "# mutual_info_columns = sorted([(list(columns), float(score[0])) for columns, score in zip(column_combinations, mutual_info_scores)], key=lambda x: x[1], reverse=True)\n",
    "# # Iterate over 20% of the most correlated columns and choose column with the lowest variance to drop\n",
    "# column_ratio = int(len(mutual_info_columns) * 0.2)\n",
    "# columns_drop = []\n",
    "# for columns, value in mutual_info_columns[:column_ratio]:\n",
    "#     index = df[columns].var().argmin()\n",
    "#     columns_drop.append(columns[index])\n",
    "# columns_drop = list(set(columns_drop))\n",
    "# df = drop_columns(df=df, columns=columns_drop)\n",
    "\n",
    "# # Show remaining columns\n",
    "# print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop columns that have low correlation with the target\n",
    "# # Numerical columns\n",
    "# selector = SelectPercentile(score_func=mutual_info_classif, percentile=30)\n",
    "# mask = selector.fit(df[numerical_columns], df[target_column]).get_support()\n",
    "# unselected_columns = [column for column, drop in zip(numerical_columns, mask) if not drop]\n",
    "# df = drop_columns(df=df, columns=unselected_columns)\n",
    "\n",
    "# # Categorical columns\n",
    "# encoder = OrdinalEncoder()\n",
    "# selector = SelectPercentile(score_func=lambda X, y: mutual_info_classif(X, y, discrete_features=True), percentile=30)\n",
    "# mask = selector.fit(encoder.fit_transform(df[categorical_columns]), df[target_column]).get_support()\n",
    "# unselected_columns = [column for column, drop in zip(categorical_columns, mask) if not drop]\n",
    "# df = drop_columns(df=df, columns=unselected_columns)\n",
    "\n",
    "# # Show remaining columns\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform non-normal distribution\n",
    "# # Plot distributions before transformation\n",
    "# plot_distributions(df, numerical_columns)\n",
    "\n",
    "# # Print Skrew and Kurtosis\n",
    "# for column in df[numerical_columns]:\n",
    "#     print(f'Column: {column}, Skew: {skew(df[column])}, Kurtosis: {kurtosis(df[column])}')\n",
    "\n",
    "# # transformer = PowerTransformer()\n",
    "# transformer = QuantileTransformer(output_distribution='normal')\n",
    "# df[numerical_columns] = transformer.fit_transform(df[numerical_columns])\n",
    "\n",
    "# # Plot distributions after transformation\n",
    "# plot_distributions(df, numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.9225847115081595\n",
      "Presicion: 0.9716392512762337\n",
      "Recall: 0.38168449197860965\n",
      "F1: 0.5480723084306511\n",
      "ROC AUC: 0.6900610814291787\n",
      "Confusion Matrix:\n",
      "[[63907   100]\n",
      " [ 5550  3426]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Split dataset in train and test data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=[target_column]), df[target_column], test_size=0.2)\n",
    "X_train, X_test, y_train, y_test = df.drop(columns=[target_column]), df.drop(columns=[target_column]), df[target_column], df[target_column]\n",
    "\n",
    "# Train classifier and predict data \n",
    "clf = XGBClassifier(enable_categorical=True)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Print metrics\n",
    "print(f'Accuracy:{accuracy}')\n",
    "print(f'Presicion: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1: {f1}')\n",
    "print(f'ROC AUC: {roc_auc}')\n",
    "print('Confusion Matrix:')\n",
    "print(f'{confusion_mat}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(df_train.drop(columns=[\"RefId\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[\"RefId\"].astype(int)\n",
    "df_train = pd.concat([df_train, pd.DataFrame(y_pred, columns=[target_column])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('../results/DontGetKicked/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
